{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AI Agents Project","text":"<p>Welcome to the AI Agents Project documentation. This project leverages IBM Orchestrate as the core agent platform to build intelligent, autonomous agents that can communicate and collaborate effectively.</p>"},{"location":"#what-are-ai-agents","title":"What are AI Agents?","text":"<p>AI Agents are autonomous software entities that can perceive their environment, make decisions, and take actions to achieve specific goals. They combine artificial intelligence capabilities with the ability to interact with various systems, tools, and other agents.</p>"},{"location":"#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Autonomy: Agents operate independently without constant human intervention</li> <li>Reactivity: They respond to changes in their environment in real-time</li> <li>Proactivity: Agents take initiative to achieve their goals</li> <li>Social Ability: They can communicate and collaborate with other agents and humans</li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>Our AI agent platform is built on IBM Orchestrate, which provides a robust foundation for agent orchestration, workflow management, and integration capabilities.</p>"},{"location":"#protocol-integration-mcp-and-a2a","title":"Protocol Integration: MCP and A2A","text":"<p>The following diagram illustrates the relationship between the Model Context Protocol (MCP) and Agent-to-Agent (A2A) communication within the IBM Orchestrate platform:</p> <pre><code>graph TB\n    subgraph \"IBM Orchestrate Platform\"\n        O[IBM Orchestrate Core]\n        AM[Agent Manager]\n        WE[Workflow Engine]\n    end\n\n    subgraph \"MCP Layer\"\n        MCP[Model Context Protocol]\n        CM[Context Manager]\n        MM[Model Manager]\n    end\n\n    subgraph \"A2A Layer\"\n        A2A[Agent-to-Agent Protocol]\n        MB[Message Bus]\n        AR[Agent Registry]\n    end\n\n    subgraph \"AI Agents\"\n        A1[Agent 1]\n        A2[Agent 2]\n        A3[Agent 3]\n    end\n\n    subgraph \"External Systems\"\n        LLM[LLM Services]\n        API[External APIs]\n        DB[(Databases)]\n    end\n\n    O --&gt; AM\n    O --&gt; WE\n    AM --&gt; MCP\n    AM --&gt; A2A\n\n    MCP --&gt; CM\n    MCP --&gt; MM\n    MM --&gt; LLM\n    CM --&gt; DB\n\n    A2A --&gt; MB\n    A2A --&gt; AR\n\n    A1 --&gt; MCP\n    A2 --&gt; MCP\n    A3 --&gt; MCP\n\n    A1 &lt;--&gt; MB\n    A2 &lt;--&gt; MB\n    A3 &lt;--&gt; MB\n\n    MB --&gt; A2A\n    AR --&gt; A2A\n\n    WE --&gt; API\n\n    style O fill:#0f62fe\n    style MCP fill:#24a148\n    style A2A fill:#ff832b</code></pre>"},{"location":"#protocol-descriptions","title":"Protocol Descriptions","text":""},{"location":"#model-context-protocol-mcp","title":"Model Context Protocol (MCP)","text":"<p>MCP provides a standardized way for agents to interact with AI models and manage context:</p> <ul> <li>Context Management: Maintains conversation history and relevant information</li> <li>Model Abstraction: Provides a unified interface to various LLM providers</li> <li>State Persistence: Ensures context is preserved across interactions</li> </ul>"},{"location":"#agent-to-agent-protocol-a2a","title":"Agent-to-Agent Protocol (A2A)","text":"<p>A2A enables seamless communication and collaboration between agents:</p> <ul> <li>Message Routing: Efficiently routes messages between agents</li> <li>Agent Discovery: Allows agents to find and connect with other agents</li> <li>Coordination: Facilitates collaborative task execution</li> </ul>"},{"location":"#featured-implementation-a2a-rag-agent","title":"Featured Implementation: A2A RAG Agent","text":"<p>We've built a production-ready Retrieval-Augmented Generation (RAG) agent that demonstrates the power of combining A2A protocol with modern AI capabilities:</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>A2A Protocol Integration: Full implementation of Agent-to-Agent communication</li> <li>MCP Server: RESTful API with 9 endpoints for RAG operations</li> <li>Watsonx.ai Integration: IBM's AI platform for embeddings and LLM services</li> <li>Milvus Vector Store: High-performance semantic search with COSINE similarity</li> <li>LangGraph Workflows: State machine orchestration for complex agent behaviors</li> <li>Production-Ready: 100% test coverage (34/34 tests passing)</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>cd RAG\n./scripts/start_services.sh\ncurl -X POST http://localhost:8000/tools/rag_query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"What is the A2A protocol?\"}'\n</code></pre> <p>Get Started with RAG Agent \u2192</p>"},{"location":"#explore-the-documentation","title":"Explore the Documentation","text":""},{"location":"#rag-agent-documentation","title":"RAG Agent Documentation","text":"<ul> <li>Overview - Architecture and components</li> <li>Quick Start - Installation and setup</li> <li>API Reference - Complete API documentation</li> <li>Configuration - Configuration and tuning</li> <li>Testing - Testing guide and results</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"#platform-documentation","title":"Platform Documentation","text":"<ol> <li>Architecture Overview - System architecture</li> <li>IBM Orchestrate - Orchestration platform</li> <li>MCP Protocol - Model Context Protocol</li> <li>A2A Communication - Agent-to-Agent Protocol</li> </ol>"},{"location":"#project-status","title":"Project Status","text":"Component Status Tests Documentation A2A RAG Agent \u2705 Complete 34/34 passing \u2705 Complete MCP Server \u2705 Complete 18/18 passing \u2705 Complete Watsonx.ai Integration \u2705 Complete Tested \u2705 Complete Milvus Vector Store \u2705 Complete Tested \u2705 Complete"},{"location":"#benefits","title":"Benefits","text":"<ul> <li>Scalability: Build agents that can handle increasing workloads</li> <li>Flexibility: Integrate with various AI models and external systems</li> <li>Reliability: Leverage IBM Orchestrate's enterprise-grade infrastructure</li> <li>Collaboration: Enable agents to work together on complex tasks</li> <li>Production-Ready: Comprehensive testing, monitoring, and deployment automation</li> </ul> <p>Powered by IBM Orchestrate</p>"},{"location":"architecture/orchestrate/","title":"IBM Orchestrate Integration","text":""},{"location":"architecture/orchestrate/#overview","title":"Overview","text":"<p>IBM Orchestrate serves as the core platform for our AI agent system, providing enterprise-grade orchestration, workflow management, and integration capabilities. It acts as the central nervous system that coordinates agent activities, manages workflows, and connects to external services.</p>"},{"location":"architecture/orchestrate/#why-ibm-orchestrate","title":"Why IBM Orchestrate?","text":"<p>IBM Orchestrate was chosen as the foundation for several key reasons:</p>"},{"location":"architecture/orchestrate/#enterprise-grade-reliability","title":"Enterprise-Grade Reliability","text":"<ul> <li>High Availability: Built-in redundancy and failover mechanisms</li> <li>Scalability: Handles thousands of concurrent workflows</li> <li>Performance: Optimized for low-latency operations</li> <li>Monitoring: Comprehensive observability and alerting</li> </ul>"},{"location":"architecture/orchestrate/#integration-capabilities","title":"Integration Capabilities","text":"<ul> <li>Pre-built Connectors: Connect to 100+ enterprise systems</li> <li>API Gateway: Unified interface for external services</li> <li>Data Transformation: Built-in data mapping and transformation</li> <li>Event Processing: Real-time event handling and routing</li> </ul>"},{"location":"architecture/orchestrate/#workflow-management","title":"Workflow Management","text":"<ul> <li>Visual Designer: Create workflows with drag-and-drop interface</li> <li>Version Control: Track and manage workflow versions</li> <li>Testing Tools: Built-in testing and debugging capabilities</li> <li>Deployment: Automated deployment pipelines</li> </ul>"},{"location":"architecture/orchestrate/#architecture-integration","title":"Architecture Integration","text":"<pre><code>graph TB\n    subgraph \"AI Agent Platform\"\n        AM[Agent Manager]\n        WM[Workflow Manager]\n        CM[Context Manager]\n    end\n\n    subgraph \"IBM Orchestrate\"\n        OC[Orchestrate Core]\n        WE[Workflow Engine]\n        IM[Integration Manager]\n        EM[Event Manager]\n        SM[Security Manager]\n    end\n\n    subgraph \"Agents\"\n        A1[Agent 1]\n        A2[Agent 2]\n        A3[Agent 3]\n    end\n\n    subgraph \"External Systems\"\n        CRM[CRM Systems]\n        ERP[ERP Systems]\n        DB[(Databases)]\n        API[External APIs]\n        CLOUD[Cloud Services]\n    end\n\n    AM --&gt; OC\n    WM --&gt; WE\n    CM --&gt; OC\n\n    OC --&gt; A1\n    OC --&gt; A2\n    OC --&gt; A3\n\n    WE --&gt; IM\n    IM --&gt; CRM\n    IM --&gt; ERP\n    IM --&gt; DB\n    IM --&gt; API\n    IM --&gt; CLOUD\n\n    EM --&gt; OC\n    SM --&gt; OC\n\n    A1 --&gt; EM\n    A2 --&gt; EM\n    A3 --&gt; EM\n\n    style OC fill:#0f62fe\n    style WE fill:#0f62fe\n    style IM fill:#0f62fe</code></pre>"},{"location":"architecture/orchestrate/#key-features","title":"Key Features","text":""},{"location":"architecture/orchestrate/#1-workflow-orchestration","title":"1. Workflow Orchestration","text":"<p>IBM Orchestrate manages complex workflows that coordinate multiple agents and services:</p> <pre><code>workflow:\n  name: customer-inquiry-handler\n  trigger: incoming-message\n  steps:\n    - name: classify-inquiry\n      agent: classification-agent\n      timeout: 5s\n\n    - name: route-to-specialist\n      agent: routing-agent\n      input: ${classify-inquiry.output}\n\n    - name: process-inquiry\n      agent: ${route-to-specialist.specialist}\n      input: ${classify-inquiry.context}\n\n    - name: send-response\n      action: send-message\n      input: ${process-inquiry.response}\n</code></pre>"},{"location":"architecture/orchestrate/#2-agent-lifecycle-management","title":"2. Agent Lifecycle Management","text":"<p>Orchestrate handles the complete agent lifecycle:</p> <ul> <li>Provisioning: Automatic agent deployment and configuration</li> <li>Scaling: Dynamic scaling based on workload</li> <li>Health Monitoring: Continuous health checks and recovery</li> <li>Decommissioning: Graceful shutdown and cleanup</li> </ul>"},{"location":"architecture/orchestrate/#3-event-driven-architecture","title":"3. Event-Driven Architecture","text":"<p>Support for event-driven patterns:</p> <ul> <li>Event Subscriptions: Agents subscribe to relevant events</li> <li>Event Routing: Intelligent routing based on event types</li> <li>Event Transformation: Convert events between formats</li> <li>Event Replay: Replay events for debugging or recovery</li> </ul>"},{"location":"architecture/orchestrate/#4-security-and-compliance","title":"4. Security and Compliance","text":"<p>Enterprise security features:</p> <ul> <li>Authentication: OAuth 2.0, SAML, API keys</li> <li>Authorization: Role-based access control (RBAC)</li> <li>Encryption: End-to-end encryption for data in transit</li> <li>Audit Logging: Comprehensive audit trails</li> <li>Compliance: SOC 2, GDPR, HIPAA compliance</li> </ul>"},{"location":"architecture/orchestrate/#configuration","title":"Configuration","text":""},{"location":"architecture/orchestrate/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from orchestrate import OrchestratePlatform\n\n# Initialize Orchestrate connection\norchestrate = OrchestratePlatform(\n    api_key=os.getenv('ORCHESTRATE_API_KEY'),\n    endpoint=os.getenv('ORCHESTRATE_ENDPOINT'),\n    workspace_id=os.getenv('ORCHESTRATE_WORKSPACE_ID')\n)\n\n# Register an agent\norchestrate.register_agent(\n    name='customer-service-agent',\n    type='conversational',\n    capabilities=['chat', 'email', 'ticket-management'],\n    max_instances=10\n)\n</code></pre>"},{"location":"architecture/orchestrate/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Configure workflow with error handling\nworkflow = orchestrate.create_workflow(\n    name='order-processing',\n    retry_policy={\n        'max_attempts': 3,\n        'backoff': 'exponential',\n        'initial_delay': 1000\n    },\n    error_handlers={\n        'timeout': 'notify-admin',\n        'validation_error': 'return-to-user',\n        'system_error': 'escalate'\n    }\n)\n</code></pre>"},{"location":"architecture/orchestrate/#integration-patterns","title":"Integration Patterns","text":""},{"location":"architecture/orchestrate/#1-request-response-pattern","title":"1. Request-Response Pattern","text":"<p>Synchronous communication for immediate responses:</p> <pre><code>response = orchestrate.invoke_agent(\n    agent_id='classification-agent',\n    input={'text': 'Customer inquiry text'},\n    timeout=5000\n)\n</code></pre>"},{"location":"architecture/orchestrate/#2-fire-and-forget-pattern","title":"2. Fire-and-Forget Pattern","text":"<p>Asynchronous processing for long-running tasks:</p> <pre><code>orchestrate.submit_task(\n    agent_id='data-processing-agent',\n    input={'dataset': 'large-dataset.csv'},\n    callback_url='https://api.example.com/callback'\n)\n</code></pre>"},{"location":"architecture/orchestrate/#3-pub-sub-pattern","title":"3. Pub-Sub Pattern","text":"<p>Event-driven communication:</p> <pre><code>orchestrate.subscribe(\n    agent_id='notification-agent',\n    events=['order.created', 'order.updated'],\n    handler=handle_order_event\n)\n</code></pre>"},{"location":"architecture/orchestrate/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"architecture/orchestrate/#metrics","title":"Metrics","text":"<p>IBM Orchestrate provides comprehensive metrics:</p> <ul> <li>Agent Performance: Response times, success rates, error rates</li> <li>Workflow Execution: Duration, step completion, bottlenecks</li> <li>Resource Usage: CPU, memory, network utilization</li> <li>Integration Health: External service availability and latency</li> </ul>"},{"location":"architecture/orchestrate/#logging","title":"Logging","text":"<p>Structured logging for debugging and analysis:</p> <pre><code>orchestrate.logger.info(\n    'Agent invoked',\n    agent_id='customer-service-agent',\n    request_id='req-12345',\n    user_id='user-67890'\n)\n</code></pre>"},{"location":"architecture/orchestrate/#alerting","title":"Alerting","text":"<p>Configure alerts for critical events:</p> <pre><code>orchestrate.create_alert(\n    name='high-error-rate',\n    condition='error_rate &gt; 0.05',\n    notification_channels=['email', 'slack'],\n    severity='critical'\n)\n</code></pre>"},{"location":"architecture/orchestrate/#best-practices","title":"Best Practices","text":""},{"location":"architecture/orchestrate/#1-workflow-design","title":"1. Workflow Design","text":"<ul> <li>Keep workflows modular and reusable</li> <li>Implement proper error handling</li> <li>Use timeouts to prevent hanging operations</li> <li>Design for idempotency</li> </ul>"},{"location":"architecture/orchestrate/#2-agent-configuration","title":"2. Agent Configuration","text":"<ul> <li>Set appropriate resource limits</li> <li>Configure health checks</li> <li>Implement graceful degradation</li> <li>Use circuit breakers for external services</li> </ul>"},{"location":"architecture/orchestrate/#3-security","title":"3. Security","text":"<ul> <li>Rotate API keys regularly</li> <li>Use least-privilege access</li> <li>Encrypt sensitive data</li> <li>Implement rate limiting</li> </ul>"},{"location":"architecture/orchestrate/#4-performance","title":"4. Performance","text":"<ul> <li>Cache frequently accessed data</li> <li>Use async operations where possible</li> <li>Implement connection pooling</li> <li>Monitor and optimize bottlenecks</li> </ul>"},{"location":"architecture/orchestrate/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/orchestrate/#common-issues","title":"Common Issues","text":"<p>Issue: Agent not responding</p> <p>Solution: Check agent health status and logs in Orchestrate dashboard</p> <p>Issue: Workflow timeout</p> <p>Solution: Increase timeout values or optimize workflow steps</p> <p>Issue: Integration failures</p> <p>Solution: Verify external service credentials and network connectivity</p>"},{"location":"architecture/orchestrate/#resources","title":"Resources","text":"<ul> <li>IBM Orchestrate Documentation</li> <li>API Reference</li> <li>MCP Protocol</li> <li>A2A Protocol</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":""},{"location":"architecture/overview/#system-architecture","title":"System Architecture","text":"<p>The AI Agents platform is built on a modular, scalable architecture that leverages IBM Orchestrate as its core orchestration engine. The system is designed to support multiple autonomous agents that can communicate, collaborate, and integrate with external services.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Presentation Layer\"\n        UI[Web Interface]\n        API[REST API]\n        CLI[Command Line Interface]\n    end\n\n    subgraph \"Application Layer\"\n        AM[Agent Manager]\n        WM[Workflow Manager]\n        CM[Context Manager]\n        MM[Message Manager]\n    end\n\n    subgraph \"IBM Orchestrate Core\"\n        OE[Orchestration Engine]\n        WE[Workflow Engine]\n        IM[Integration Manager]\n    end\n\n    subgraph \"Protocol Layer\"\n        MCP[Model Context Protocol]\n        A2A[Agent-to-Agent Protocol]\n    end\n\n    subgraph \"Agent Layer\"\n        A1[Agent Instance 1]\n        A2[Agent Instance 2]\n        AN[Agent Instance N]\n    end\n\n    subgraph \"Data Layer\"\n        DB[(Database)]\n        CACHE[(Cache)]\n        QUEUE[(Message Queue)]\n    end\n\n    subgraph \"External Services\"\n        LLM[LLM Services]\n        EXT[External APIs]\n        TOOLS[Tools &amp; Services]\n    end\n\n    UI --&gt; API\n    CLI --&gt; API\n    API --&gt; AM\n    API --&gt; WM\n\n    AM --&gt; OE\n    WM --&gt; WE\n    CM --&gt; OE\n    MM --&gt; OE\n\n    OE --&gt; MCP\n    OE --&gt; A2A\n    WE --&gt; IM\n\n    MCP --&gt; A1\n    MCP --&gt; A2\n    MCP --&gt; AN\n\n    A2A --&gt; A1\n    A2A --&gt; A2\n    A2A --&gt; AN\n\n    A1 --&gt; DB\n    A2 --&gt; DB\n    AN --&gt; DB\n\n    MM --&gt; QUEUE\n    CM --&gt; CACHE\n\n    MCP --&gt; LLM\n    IM --&gt; EXT\n    A1 --&gt; TOOLS\n    A2 --&gt; TOOLS\n    AN --&gt; TOOLS\n\n    style OE fill:#0f62fe\n    style MCP fill:#24a148\n    style A2A fill:#ff832b</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#1-presentation-layer","title":"1. Presentation Layer","text":"<p>The presentation layer provides multiple interfaces for interacting with the platform:</p> <ul> <li>Web Interface: User-friendly dashboard for managing agents</li> <li>REST API: Programmatic access for integrations</li> <li>CLI: Command-line tools for developers and administrators</li> </ul>"},{"location":"architecture/overview/#2-application-layer","title":"2. Application Layer","text":"<p>The application layer contains the business logic:</p> <ul> <li>Agent Manager: Handles agent lifecycle (creation, deployment, monitoring)</li> <li>Workflow Manager: Orchestrates complex multi-step processes</li> <li>Context Manager: Maintains state and context across interactions</li> <li>Message Manager: Routes and manages inter-agent communication</li> </ul>"},{"location":"architecture/overview/#3-ibm-orchestrate-core","title":"3. IBM Orchestrate Core","text":"<p>IBM Orchestrate provides the foundation:</p> <ul> <li>Orchestration Engine: Coordinates agent activities and workflows</li> <li>Workflow Engine: Executes predefined and dynamic workflows</li> <li>Integration Manager: Connects to external systems and services</li> </ul>"},{"location":"architecture/overview/#4-protocol-layer","title":"4. Protocol Layer","text":"<p>Two key protocols enable agent functionality:</p> <ul> <li>Model Context Protocol (MCP): Standardizes AI model interactions</li> <li>Agent-to-Agent Protocol (A2A): Facilitates inter-agent communication</li> </ul>"},{"location":"architecture/overview/#5-agent-layer","title":"5. Agent Layer","text":"<p>Individual agent instances that:</p> <ul> <li>Execute specific tasks and responsibilities</li> <li>Maintain their own state and context</li> <li>Communicate with other agents</li> <li>Integrate with external tools and services</li> </ul>"},{"location":"architecture/overview/#6-data-layer","title":"6. Data Layer","text":"<p>Persistent storage and caching:</p> <ul> <li>Database: Stores agent configurations, logs, and state</li> <li>Cache: Improves performance for frequently accessed data</li> <li>Message Queue: Ensures reliable asynchronous communication</li> </ul>"},{"location":"architecture/overview/#design-principles","title":"Design Principles","text":""},{"location":"architecture/overview/#modularity","title":"Modularity","text":"<p>Each component is designed to be independent and replaceable, allowing for:</p> <ul> <li>Easy maintenance and updates</li> <li>Component-level scaling</li> <li>Technology stack flexibility</li> </ul>"},{"location":"architecture/overview/#scalability","title":"Scalability","text":"<p>The architecture supports horizontal scaling:</p> <ul> <li>Multiple agent instances can run concurrently</li> <li>Load balancing across agent pools</li> <li>Distributed processing capabilities</li> </ul>"},{"location":"architecture/overview/#reliability","title":"Reliability","text":"<p>Built-in resilience features:</p> <ul> <li>Automatic retry mechanisms</li> <li>Circuit breakers for external services</li> <li>State persistence and recovery</li> </ul>"},{"location":"architecture/overview/#security","title":"Security","text":"<p>Security is integrated at every layer:</p> <ul> <li>Authentication and authorization</li> <li>Encrypted communication</li> <li>Audit logging</li> <li>Secure credential management</li> </ul>"},{"location":"architecture/overview/#communication-patterns","title":"Communication Patterns","text":""},{"location":"architecture/overview/#synchronous-communication","title":"Synchronous Communication","text":"<p>Used for immediate responses:</p> <ul> <li>REST API calls</li> <li>Direct agent-to-agent messages</li> <li>Real-time user interactions</li> </ul>"},{"location":"architecture/overview/#asynchronous-communication","title":"Asynchronous Communication","text":"<p>Used for long-running tasks:</p> <ul> <li>Message queue processing</li> <li>Background job execution</li> <li>Event-driven workflows</li> </ul>"},{"location":"architecture/overview/#deployment-models","title":"Deployment Models","text":""},{"location":"architecture/overview/#single-instance","title":"Single Instance","text":"<p>Suitable for development and testing:</p> <ul> <li>All components on one machine</li> <li>Simplified configuration</li> <li>Easy debugging</li> </ul>"},{"location":"architecture/overview/#distributed","title":"Distributed","text":"<p>Recommended for production:</p> <ul> <li>Components across multiple servers</li> <li>Load balancing and redundancy</li> <li>High availability configuration</li> </ul>"},{"location":"architecture/overview/#cloud-native","title":"Cloud-Native","text":"<p>Optimized for cloud platforms:</p> <ul> <li>Containerized deployments</li> <li>Auto-scaling capabilities</li> <li>Managed services integration</li> </ul>"},{"location":"architecture/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more about IBM Orchestrate Integration</li> <li>Explore the MCP Protocol</li> <li>Understand A2A Communication</li> </ul>"},{"location":"deployment/ibm-code-engine/","title":"IBM Code Engine Deployment","text":"<p>This guide covers deploying the RAG agents (MCP Server and A2A Agent) to IBM Code Engine.</p>"},{"location":"deployment/ibm-code-engine/#overview","title":"Overview","text":"<p>The deployment package provides a complete, production-ready solution for containerizing and deploying both the MCP Server and A2A Agent to IBM Cloud Code Engine using Red Hat UBI 10 micro base images.</p>"},{"location":"deployment/ibm-code-engine/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"IBM Code Engine\"\n        MCP[MCP Server&lt;br/&gt;FastAPI&lt;br/&gt;Port: 8000]\n        A2A[A2A Agent&lt;br/&gt;LangGraph&lt;br/&gt;Port: 8001]\n        A2A --&gt;|HTTP| MCP\n    end\n\n    MCP --&gt;|API| WX[Watsonx.ai&lt;br/&gt;Embeddings + LLM]\n    MCP --&gt;|Vector DB| MV[Milvus&lt;br/&gt;External]\n\n    style MCP fill:#4285f4\n    style A2A fill:#34a853\n    style WX fill:#fbbc04\n    style MV fill:#ea4335</code></pre>"},{"location":"deployment/ibm-code-engine/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/ibm-code-engine/#required-services","title":"Required Services","text":"<ol> <li>IBM Cloud Account with access to:</li> <li>IBM Cloud Container Registry</li> <li>IBM Code Engine</li> <li> <p>IBM Watsonx.ai</p> </li> <li> <p>IBM Cloud CLI with plugins:    <pre><code>ibmcloud plugin install container-registry\nibmcloud plugin install code-engine\n</code></pre></p> </li> <li> <p>Podman (or Docker) installed locally</p> </li> <li> <p>External Milvus Instance for vector storage</p> </li> </ol>"},{"location":"deployment/ibm-code-engine/#required-credentials","title":"Required Credentials","text":"<ul> <li>IBM Cloud API key</li> <li>Watsonx.ai API key and project ID</li> <li>Milvus host and port</li> <li>Container Registry namespace</li> </ul>"},{"location":"deployment/ibm-code-engine/#quick-start","title":"Quick Start","text":""},{"location":"deployment/ibm-code-engine/#1-configure-environment","title":"1. Configure Environment","text":"<pre><code>cd RAG/deployment/ibm-code-engine\n\n# Copy environment template\ncp .env.example .env\n\n# Edit with your credentials\nnano .env\n</code></pre>"},{"location":"deployment/ibm-code-engine/#2-deploy-services","title":"2. Deploy Services","text":"<pre><code># Deploy both MCP Server and A2A Agent\n./deploy-all.sh\n\n# Or deploy individually\ncd mcp-server &amp;&amp; ./deploy.sh\ncd a2a-agent &amp;&amp; ./deploy.sh\n</code></pre>"},{"location":"deployment/ibm-code-engine/#3-verify-deployment","title":"3. Verify Deployment","text":"<pre><code># List applications\nibmcloud ce application list\n\n# Check health\ncurl https://rag-mcp-server.your-region.codeengine.appdomain.cloud/health\n\n# View logs\nibmcloud ce application logs -n rag-mcp-server\n</code></pre>"},{"location":"deployment/ibm-code-engine/#configuration","title":"Configuration","text":""},{"location":"deployment/ibm-code-engine/#environment-variables","title":"Environment Variables","text":""},{"location":"deployment/ibm-code-engine/#required-variables","title":"Required Variables","text":"Variable Description Example <code>TZ_RESOURCE_GROUP</code> IBM Cloud resource group <code>default</code> <code>TZ_ICR</code> Container registry URL <code>de.icr.io</code> <code>TZ_NAMESPACE</code> Registry namespace <code>my-namespace</code> <code>TZ_ICE_PROJECT</code> Code Engine project name <code>rag-project</code> <code>TZ_API_KEY</code> IBM Cloud API key <code>xxx</code> <code>WATSONX_API_KEY</code> Watsonx.ai API key <code>xxx</code> <code>WATSONX_PROJECT_ID</code> Watsonx.ai project ID <code>xxx</code> <code>WATSONX_URL</code> Watsonx.ai endpoint <code>https://us-south.ml.cloud.ibm.com</code> <code>MILVUS_HOST</code> External Milvus host <code>milvus.example.com</code> <code>MILVUS_PORT</code> Milvus port <code>19530</code>"},{"location":"deployment/ibm-code-engine/#optional-variables","title":"Optional Variables","text":"Variable Description Default <code>EMBEDDING_MODEL</code> Embedding model <code>ibm/slate-125m-english-rtrvr</code> <code>EMBEDDING_DIMENSION</code> Vector dimension <code>384</code> <code>LLM_MODEL</code> LLM model <code>ibm/granite-13b-chat-v2</code> <code>LLM_MAX_TOKENS</code> Max tokens <code>2048</code> <code>LLM_TEMPERATURE</code> Temperature <code>0.7</code> <code>RAG_CHUNK_SIZE</code> Chunk size <code>512</code> <code>RAG_CHUNK_OVERLAP</code> Chunk overlap <code>50</code> <code>RAG_TOP_K</code> Top K results <code>5</code> <code>RAG_SCORE_THRESHOLD</code> Score threshold <code>0.7</code> <code>LOG_LEVEL</code> Logging level <code>INFO</code>"},{"location":"deployment/ibm-code-engine/#deployment-components","title":"Deployment Components","text":""},{"location":"deployment/ibm-code-engine/#mcp-server","title":"MCP Server","text":"<p>The MCP Server provides the RESTful API for RAG operations.</p> <p>Container Specifications: - Base: Red Hat UBI 10 micro - Port: 8000 - Resources: 1 vCPU, 2GB RAM - Scaling: 1-3 instances - Health check: <code>/health</code> endpoint</p> <p>Key Features: - FastAPI-based REST API - 9 RAG tool endpoints - Watsonx.ai integration - Milvus vector storage - Document processing (PDF, DOCX, TXT, MD)</p>"},{"location":"deployment/ibm-code-engine/#a2a-agent","title":"A2A Agent","text":"<p>The A2A Agent orchestrates RAG workflows using LangGraph.</p> <p>Container Specifications: - Base: Red Hat UBI 10 micro - Port: 8001 - Resources: 1 vCPU, 2GB RAM - Scaling: 1-3 instances - Health check: Python-based</p> <p>Key Features: - LangGraph workflow orchestration - A2A protocol support - MCP tool client - State management - Error handling</p>"},{"location":"deployment/ibm-code-engine/#deployment-process","title":"Deployment Process","text":""},{"location":"deployment/ibm-code-engine/#mcp-server-deployment","title":"MCP Server Deployment","text":"<p>The <code>mcp-server/deploy.sh</code> script:</p> <ol> <li>Validates environment variables</li> <li>Authenticates with IBM Cloud</li> <li>Builds container image with Podman</li> <li>Pushes to IBM Container Registry</li> <li>Creates/updates Code Engine application</li> <li>Configures environment variables</li> <li>Tests health endpoint</li> <li>Reports deployment status</li> </ol>"},{"location":"deployment/ibm-code-engine/#a2a-agent-deployment","title":"A2A Agent Deployment","text":"<p>The <code>a2a-agent/deploy.sh</code> script:</p> <ol> <li>Validates environment variables</li> <li>Authenticates with IBM Cloud</li> <li>Builds container image with Podman</li> <li>Pushes to IBM Container Registry</li> <li>Creates/updates Code Engine application</li> <li>Configures environment variables</li> <li>Links to MCP Server</li> <li>Reports deployment status</li> </ol>"},{"location":"deployment/ibm-code-engine/#master-deployment","title":"Master Deployment","text":"<p>The <code>deploy-all.sh</code> script orchestrates both deployments:</p> <ol> <li>Deploys MCP Server</li> <li>Waits for MCP Server readiness (30s)</li> <li>Deploys A2A Agent</li> <li>Provides deployment summary</li> </ol>"},{"location":"deployment/ibm-code-engine/#container-images","title":"Container Images","text":""},{"location":"deployment/ibm-code-engine/#multi-stage-build","title":"Multi-Stage Build","text":"<p>Both containers use multi-stage builds for minimal image size:</p> <pre><code># Stage 1: Build environment\nFROM registry.access.redhat.com/ubi10 AS build\n# Install dependencies and build application\n\n# Stage 2: Minimal runtime\nFROM scratch AS image\n# Copy only runtime artifacts\n</code></pre> <p>Benefits: - Minimal image size - Reduced attack surface - Faster deployment - Lower storage costs</p>"},{"location":"deployment/ibm-code-engine/#security-features","title":"Security Features","text":"<ul> <li>Non-root user (UID 1001)</li> <li>Minimal base image (UBI micro)</li> <li>No shell or package manager</li> <li>Read-only root filesystem compatible</li> </ul>"},{"location":"deployment/ibm-code-engine/#scaling","title":"Scaling","text":""},{"location":"deployment/ibm-code-engine/#auto-scaling-configuration","title":"Auto-Scaling Configuration","text":"<p>Both services auto-scale based on load:</p> <ul> <li>Minimum instances: 1</li> <li>Maximum instances: 3</li> <li>CPU: 1 vCPU per instance</li> <li>Memory: 2 GB per instance</li> </ul>"},{"location":"deployment/ibm-code-engine/#modify-scaling","title":"Modify Scaling","text":"<pre><code># Update MCP Server\nibmcloud ce application update rag-mcp-server \\\n  --min-scale 2 --max-scale 5 \\\n  --cpu 2 --memory 4G\n\n# Update A2A Agent\nibmcloud ce application update rag-a2a-agent \\\n  --min-scale 2 --max-scale 5 \\\n  --cpu 2 --memory 4G\n</code></pre>"},{"location":"deployment/ibm-code-engine/#scale-to-zero","title":"Scale to Zero","text":"<p>For development environments, you can enable scale-to-zero:</p> <pre><code>ibmcloud ce application update rag-mcp-server --min-scale 0\n</code></pre> <p>Production Consideration</p> <p>Scale-to-zero is not recommended for production as it introduces cold start latency.</p>"},{"location":"deployment/ibm-code-engine/#monitoring","title":"Monitoring","text":""},{"location":"deployment/ibm-code-engine/#application-logs","title":"Application Logs","text":"<pre><code># Real-time logs\nibmcloud ce application logs -n rag-mcp-server -f\nibmcloud ce application logs -n rag-a2a-agent -f\n\n# Recent logs (last 100 lines)\nibmcloud ce application logs -n rag-mcp-server --tail 100\n</code></pre>"},{"location":"deployment/ibm-code-engine/#application-status","title":"Application Status","text":"<pre><code># Detailed status\nibmcloud ce application get -n rag-mcp-server\nibmcloud ce application get -n rag-a2a-agent\n\n# List all applications\nibmcloud ce application list\n\n# Application events\nibmcloud ce application events -n rag-mcp-server\n</code></pre>"},{"location":"deployment/ibm-code-engine/#health-checks","title":"Health Checks","text":"<pre><code># MCP Server health\ncurl https://rag-mcp-server.your-region.codeengine.appdomain.cloud/health\n\n# Expected response\n{\n  \"status\": \"healthy\",\n  \"components\": {\n    \"watsonx\": true,\n    \"milvus\": true,\n    \"document_processor\": true\n  }\n}\n\n# MCP Server statistics\ncurl https://rag-mcp-server.your-region.codeengine.appdomain.cloud/tools/rag_stats\n</code></pre>"},{"location":"deployment/ibm-code-engine/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/ibm-code-engine/#container-build-issues","title":"Container Build Issues","text":"<p>Problem: Build fails with dependency errors</p> <pre><code># Clean build cache\npodman system prune -a\n\n# Rebuild with no cache\npodman build -f Containerfile --no-cache .\n\n# Check Podman version\npodman --version  # Should be 4.0+\n</code></pre>"},{"location":"deployment/ibm-code-engine/#deployment-failures","title":"Deployment Failures","text":"<p>Problem: Deployment script fails</p> <pre><code># Verify IBM Cloud login\nibmcloud target\n\n# Check Code Engine project\nibmcloud ce project list\nibmcloud ce project select --name your-project\n\n# Verify registry access\nibmcloud cr login\nibmcloud cr namespace-list\n</code></pre>"},{"location":"deployment/ibm-code-engine/#application-not-starting","title":"Application Not Starting","text":"<p>Problem: Application shows as failed</p> <pre><code># Check application logs\nibmcloud ce application logs -n rag-mcp-server\n\n# Check application events\nibmcloud ce application events -n rag-mcp-server\n\n# Verify environment variables\nibmcloud ce application get -n rag-mcp-server -o yaml\n</code></pre>"},{"location":"deployment/ibm-code-engine/#milvus-connection-issues","title":"Milvus Connection Issues","text":"<p>Problem: Cannot connect to Milvus</p> <ul> <li>Verify Milvus is accessible from Code Engine</li> <li>Check <code>MILVUS_HOST</code> and <code>MILVUS_PORT</code> in <code>.env</code></li> <li>Test connectivity: <code>curl http://MILVUS_HOST:MILVUS_PORT/health</code></li> <li>Ensure firewall rules allow Code Engine egress</li> </ul>"},{"location":"deployment/ibm-code-engine/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging:</p> <pre><code>ibmcloud ce application update rag-mcp-server \\\n  --env LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"deployment/ibm-code-engine/#updates-and-rollbacks","title":"Updates and Rollbacks","text":""},{"location":"deployment/ibm-code-engine/#update-deployment","title":"Update Deployment","text":"<pre><code># Update MCP Server\ncd mcp-server &amp;&amp; ./deploy.sh\n\n# Update A2A Agent\ncd a2a-agent &amp;&amp; ./deploy.sh\n</code></pre> <p>The deployment script automatically: - Builds new container image with timestamp tag - Pushes to registry - Updates Code Engine application - Performs health check</p>"},{"location":"deployment/ibm-code-engine/#rollback-to-previous-version","title":"Rollback to Previous Version","text":"<pre><code># List application revisions\nibmcloud ce application revisions -n rag-mcp-server\n\n# Rollback to specific revision\nibmcloud ce application update rag-mcp-server \\\n  --revision rag-mcp-server-00002\n</code></pre>"},{"location":"deployment/ibm-code-engine/#view-revision-history","title":"View Revision History","text":"<pre><code># Get revision details\nibmcloud ce revision get rag-mcp-server-00003\n\n# Compare revisions\nibmcloud ce revision get rag-mcp-server-00002 -o yaml &gt; rev2.yaml\nibmcloud ce revision get rag-mcp-server-00003 -o yaml &gt; rev3.yaml\ndiff rev2.yaml rev3.yaml\n</code></pre>"},{"location":"deployment/ibm-code-engine/#security","title":"Security","text":""},{"location":"deployment/ibm-code-engine/#best-practices","title":"Best Practices","text":"<ol> <li>Secrets Management</li> <li>Never commit <code>.env</code> file to version control</li> <li>Use IBM Cloud Secrets Manager for production</li> <li> <p>Rotate credentials regularly (90 days)</p> </li> <li> <p>Network Security</p> </li> <li>Use private endpoints where possible</li> <li>Configure appropriate firewall rules</li> <li> <p>Enable TLS/SSL for all connections</p> </li> <li> <p>Access Control</p> </li> <li>Apply least privilege principle</li> <li>Use IAM roles appropriately</li> <li>Enable audit logging</li> <li> <p>Review access regularly</p> </li> <li> <p>Container Security</p> </li> <li>Non-root containers (UID 1001)</li> <li>Minimal base images</li> <li>No shell or package manager</li> <li>Regular security updates</li> </ol>"},{"location":"deployment/ibm-code-engine/#secrets-in-code-engine","title":"Secrets in Code Engine","text":"<p>For production, use Code Engine secrets:</p> <pre><code># Create secret from file\nibmcloud ce secret create --name rag-secrets \\\n  --from-env-file .env\n\n# Update application to use secret\nibmcloud ce application update rag-mcp-server \\\n  --env-from-secret rag-secrets\n</code></pre>"},{"location":"deployment/ibm-code-engine/#cost-optimization","title":"Cost Optimization","text":""},{"location":"deployment/ibm-code-engine/#right-sizing-resources","title":"Right-Sizing Resources","text":"<p>Monitor actual usage and adjust:</p> <pre><code># View metrics\nibmcloud ce application get -n rag-mcp-server\n\n# Adjust based on usage\nibmcloud ce application update rag-mcp-server \\\n  --cpu 0.5 --memory 1G  # Reduce for lower load\n</code></pre>"},{"location":"deployment/ibm-code-engine/#scaling-strategy","title":"Scaling Strategy","text":"<ul> <li>Development: <code>--min-scale 0</code> (scale to zero)</li> <li>Staging: <code>--min-scale 1 --max-scale 2</code></li> <li>Production: <code>--min-scale 2 --max-scale 5</code></li> </ul>"},{"location":"deployment/ibm-code-engine/#image-optimization","title":"Image Optimization","text":"<p>Already implemented: - Multi-stage builds - Minimal base images (UBI micro) - Optimized dependencies - No unnecessary packages</p>"},{"location":"deployment/ibm-code-engine/#cleanup","title":"Cleanup","text":""},{"location":"deployment/ibm-code-engine/#delete-applications","title":"Delete Applications","text":"<pre><code># Delete MCP Server\nibmcloud ce application delete -n rag-mcp-server -f\n\n# Delete A2A Agent\nibmcloud ce application delete -n rag-a2a-agent -f\n\n# Delete registry secret\nibmcloud ce secret delete -n rag-registry-secret -f\n</code></pre>"},{"location":"deployment/ibm-code-engine/#delete-container-images","title":"Delete Container Images","text":"<pre><code># List images\nibmcloud cr image-list --restrict your-namespace\n\n# Delete specific image\nibmcloud cr image-rm de.icr.io/your-namespace/rag-mcp-server:20260119120000\n\n# Delete all images for a repository\nibmcloud cr image-rm de.icr.io/your-namespace/rag-mcp-server --force\n</code></pre>"},{"location":"deployment/ibm-code-engine/#complete-cleanup","title":"Complete Cleanup","text":"<pre><code># Delete all RAG resources\nibmcloud ce application delete -n rag-mcp-server -f\nibmcloud ce application delete -n rag-a2a-agent -f\nibmcloud ce secret delete -n rag-registry-secret -f\n\n# Clean local images\npodman rmi $(podman images | grep rag- | awk '{print $3}')\n</code></pre>"},{"location":"deployment/ibm-code-engine/#api-endpoints","title":"API Endpoints","text":""},{"location":"deployment/ibm-code-engine/#mcp-server-endpoints","title":"MCP Server Endpoints","text":"<p>Base URL: <code>https://rag-mcp-server.your-region.codeengine.appdomain.cloud</code></p> Endpoint Method Description <code>/</code> GET Server information <code>/health</code> GET Health check <code>/docs</code> GET API documentation (Swagger) <code>/tools</code> GET List available tools <code>/tools/rag_query</code> POST Query with LLM generation <code>/tools/rag_search</code> POST Semantic search only <code>/tools/rag_index</code> POST Index single document <code>/tools/rag_index_directory</code> POST Index directory <code>/tools/rag_stats</code> GET Knowledge base statistics <code>/tools/rag_clear</code> DELETE Clear knowledge base"},{"location":"deployment/ibm-code-engine/#example-api-calls","title":"Example API Calls","text":"<pre><code># Query endpoint\ncurl -X POST https://rag-mcp-server.your-region.codeengine.appdomain.cloud/tools/rag_query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"What is the A2A protocol?\",\n    \"top_k\": 5,\n    \"include_sources\": true\n  }'\n\n# Search endpoint\ncurl -X POST https://rag-mcp-server.your-region.codeengine.appdomain.cloud/tools/rag_search \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"agent communication\",\n    \"top_k\": 3\n  }'\n\n# Stats endpoint\ncurl https://rag-mcp-server.your-region.codeengine.appdomain.cloud/tools/rag_stats\n</code></pre>"},{"location":"deployment/ibm-code-engine/#performance-tuning","title":"Performance Tuning","text":""},{"location":"deployment/ibm-code-engine/#optimize-response-time","title":"Optimize Response Time","text":"<ol> <li> <p>Increase Resources <pre><code>ibmcloud ce application update rag-mcp-server \\\n  --cpu 2 --memory 4G\n</code></pre></p> </li> <li> <p>Increase Min Scale <pre><code>ibmcloud ce application update rag-mcp-server \\\n  --min-scale 2\n</code></pre></p> </li> <li> <p>Optimize RAG Parameters</p> </li> <li>Reduce <code>RAG_TOP_K</code> for faster queries</li> <li>Increase <code>RAG_SCORE_THRESHOLD</code> for better quality</li> <li>Adjust <code>RAG_CHUNK_SIZE</code> based on content</li> </ol>"},{"location":"deployment/ibm-code-engine/#monitor-performance","title":"Monitor Performance","text":"<pre><code># View application metrics\nibmcloud ce application get -n rag-mcp-server\n\n# Check response times in logs\nibmcloud ce application logs -n rag-mcp-server | grep \"response_time\"\n</code></pre>"},{"location":"deployment/ibm-code-engine/#support","title":"Support","text":"<ul> <li>Documentation: This guide and RAG Overview</li> <li>IBM Cloud Docs: Code Engine Documentation</li> <li>Troubleshooting: RAG Troubleshooting</li> <li>API Reference: RAG API Reference</li> </ul>"},{"location":"deployment/ibm-code-engine/#next-steps","title":"Next Steps","text":"<ol> <li>Review RAG Overview for system architecture</li> <li>See RAG Configuration for tuning options</li> <li>Check RAG Testing for validation procedures</li> <li>Consult RAG Troubleshooting for common issues</li> </ol>"},{"location":"protocols/a2a/","title":"Agent-to-Agent Protocol (A2A)","text":""},{"location":"protocols/a2a/#overview","title":"Overview","text":"<p>The Agent-to-Agent Protocol (A2A) enables seamless communication and collaboration between autonomous agents within the IBM Orchestrate platform. A2A provides a standardized messaging framework that allows agents to discover each other, exchange information, coordinate tasks, and work together to accomplish complex goals.</p>"},{"location":"protocols/a2a/#purpose","title":"Purpose","text":"<p>A2A solves critical challenges in multi-agent systems:</p> <ul> <li>Agent Discovery: Find and connect with other agents dynamically</li> <li>Message Routing: Efficiently route messages between agents</li> <li>Coordination: Synchronize activities across multiple agents</li> <li>Reliability: Ensure message delivery with acknowledgments and retries</li> <li>Security: Authenticate and authorize inter-agent communication</li> </ul>"},{"location":"protocols/a2a/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Agent Layer\"\n        A1[Agent 1]\n        A2[Agent 2]\n        A3[Agent 3]\n        A4[Agent 4]\n    end\n\n    subgraph \"A2A Protocol Layer\"\n        A2A[A2A Interface]\n        MB[Message Bus]\n        AR[Agent Registry]\n        MR[Message Router]\n        QM[Queue Manager]\n    end\n\n    subgraph \"Infrastructure\"\n        QUEUE[(Message Queue)]\n        CACHE[(Cache)]\n        DB[(Registry DB)]\n    end\n\n    subgraph \"IBM Orchestrate\"\n        OE[Orchestration Engine]\n        EM[Event Manager]\n    end\n\n    A1 --&gt; A2A\n    A2 --&gt; A2A\n    A3 --&gt; A2A\n    A4 --&gt; A2A\n\n    A2A --&gt; MB\n    A2A --&gt; AR\n    A2A --&gt; MR\n\n    MB --&gt; QM\n    MR --&gt; MB\n    AR --&gt; DB\n\n    QM --&gt; QUEUE\n    MB --&gt; CACHE\n\n    A2A --&gt; OE\n    OE --&gt; EM\n\n    style A2A fill:#ff832b\n    style MB fill:#ff832b\n    style AR fill:#ff832b</code></pre>"},{"location":"protocols/a2a/#core-components","title":"Core Components","text":""},{"location":"protocols/a2a/#1-agent-registry","title":"1. Agent Registry","text":"<p>Maintains a directory of all active agents:</p> <pre><code>from a2a import A2AClient\n\n# Initialize A2A client\na2a = A2AClient(\n    agent_id='customer-service-agent',\n    orchestrate_endpoint=os.getenv('ORCHESTRATE_ENDPOINT')\n)\n\n# Register agent\na2a.register(\n    capabilities=['chat', 'email', 'ticket-management'],\n    metadata={\n        'version': '1.0.0',\n        'max_concurrent_tasks': 10,\n        'specialization': 'customer-support'\n    }\n)\n\n# Discover agents\nagents = a2a.discover(\n    capability='data-analysis',\n    filters={'specialization': 'financial'}\n)\n</code></pre>"},{"location":"protocols/a2a/#2-message-bus","title":"2. Message Bus","text":"<p>Handles message routing and delivery:</p> <pre><code># Send direct message\na2a.send_message(\n    to='data-analysis-agent',\n    message={\n        'type': 'request',\n        'action': 'analyze_data',\n        'payload': {\n            'dataset': 'sales-2026-q1.csv',\n            'analysis_type': 'trend'\n        }\n    },\n    priority='high',\n    timeout=30000\n)\n\n# Broadcast message\na2a.broadcast(\n    message={\n        'type': 'notification',\n        'event': 'system_maintenance',\n        'scheduled_at': '2026-01-20T00:00:00Z'\n    },\n    filters={'capability': 'monitoring'}\n)\n</code></pre>"},{"location":"protocols/a2a/#3-message-router","title":"3. Message Router","text":"<p>Intelligently routes messages based on agent capabilities:</p> <pre><code># Route to best available agent\nresponse = a2a.route_request(\n    capability='translation',\n    message={\n        'text': 'Hello, world!',\n        'source_lang': 'en',\n        'target_lang': 'fr'\n    },\n    routing_strategy='least-loaded'\n)\n</code></pre>"},{"location":"protocols/a2a/#4-queue-manager","title":"4. Queue Manager","text":"<p>Manages message queues for reliable delivery:</p> <pre><code># Subscribe to queue\na2a.subscribe(\n    queue='customer-inquiries',\n    handler=handle_inquiry,\n    max_concurrent=5\n)\n\n# Publish to queue\na2a.publish(\n    queue='customer-inquiries',\n    message={\n        'inquiry_id': 'inq-12345',\n        'customer_id': 'cust-67890',\n        'message': 'I need help with my order'\n    }\n)\n</code></pre>"},{"location":"protocols/a2a/#protocol-specification","title":"Protocol Specification","text":""},{"location":"protocols/a2a/#message-format","title":"Message Format","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"message_id\": \"msg-abc123\",\n  \"timestamp\": \"2026-01-15T11:42:00Z\",\n  \"from\": {\n    \"agent_id\": \"customer-service-agent\",\n    \"instance_id\": \"inst-001\"\n  },\n  \"to\": {\n    \"agent_id\": \"data-analysis-agent\",\n    \"instance_id\": \"inst-002\"\n  },\n  \"type\": \"request\",\n  \"action\": \"analyze_data\",\n  \"payload\": {\n    \"dataset\": \"sales-2026-q1.csv\",\n    \"analysis_type\": \"trend\"\n  },\n  \"metadata\": {\n    \"priority\": \"high\",\n    \"timeout\": 30000,\n    \"correlation_id\": \"corr-xyz789\",\n    \"reply_to\": \"customer-service-agent\"\n  }\n}\n</code></pre>"},{"location":"protocols/a2a/#response-format","title":"Response Format","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"message_id\": \"msg-def456\",\n  \"timestamp\": \"2026-01-15T11:42:05Z\",\n  \"from\": {\n    \"agent_id\": \"data-analysis-agent\",\n    \"instance_id\": \"inst-002\"\n  },\n  \"to\": {\n    \"agent_id\": \"customer-service-agent\",\n    \"instance_id\": \"inst-001\"\n  },\n  \"type\": \"response\",\n  \"status\": \"success\",\n  \"payload\": {\n    \"analysis_results\": {\n      \"trend\": \"upward\",\n      \"growth_rate\": 15.3,\n      \"confidence\": 0.92\n    }\n  },\n  \"metadata\": {\n    \"correlation_id\": \"corr-xyz789\",\n    \"processing_time_ms\": 4850\n  }\n}\n</code></pre>"},{"location":"protocols/a2a/#error-format","title":"Error Format","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"message_id\": \"msg-ghi789\",\n  \"timestamp\": \"2026-01-15T11:42:05Z\",\n  \"from\": {\n    \"agent_id\": \"data-analysis-agent\",\n    \"instance_id\": \"inst-002\"\n  },\n  \"to\": {\n    \"agent_id\": \"customer-service-agent\",\n    \"instance_id\": \"inst-001\"\n  },\n  \"type\": \"error\",\n  \"error\": {\n    \"code\": \"INVALID_DATASET\",\n    \"message\": \"Dataset not found or inaccessible\",\n    \"details\": {\n      \"dataset\": \"sales-2026-q1.csv\",\n      \"reason\": \"file_not_found\"\n    }\n  },\n  \"metadata\": {\n    \"correlation_id\": \"corr-xyz789\"\n  }\n}\n</code></pre>"},{"location":"protocols/a2a/#communication-patterns","title":"Communication Patterns","text":""},{"location":"protocols/a2a/#1-request-response","title":"1. Request-Response","text":"<p>Synchronous communication for immediate responses:</p> <pre><code># Send request and wait for response\nresponse = a2a.request(\n    to='translation-agent',\n    action='translate',\n    payload={\n        'text': 'Hello, world!',\n        'target_lang': 'es'\n    },\n    timeout=5000\n)\n\nprint(response.payload['translated_text'])\n</code></pre>"},{"location":"protocols/a2a/#2-fire-and-forget","title":"2. Fire-and-Forget","text":"<p>Asynchronous communication without waiting for response:</p> <pre><code># Send message without waiting\na2a.send(\n    to='logging-agent',\n    action='log_event',\n    payload={\n        'event': 'user_login',\n        'user_id': 'user-123'\n    }\n)\n</code></pre>"},{"location":"protocols/a2a/#3-publish-subscribe","title":"3. Publish-Subscribe","text":"<p>Event-driven communication:</p> <pre><code># Subscribe to events\na2a.subscribe_event(\n    event_type='order.created',\n    handler=handle_new_order\n)\n\n# Publish event\na2a.publish_event(\n    event_type='order.created',\n    payload={\n        'order_id': 'ord-456',\n        'customer_id': 'cust-789',\n        'total': 99.99\n    }\n)\n</code></pre>"},{"location":"protocols/a2a/#4-request-reply-with-callback","title":"4. Request-Reply with Callback","text":"<p>Asynchronous request with callback:</p> <pre><code># Send request with callback\na2a.request_async(\n    to='data-processing-agent',\n    action='process_large_dataset',\n    payload={'dataset': 'large-data.csv'},\n    callback=handle_processing_complete\n)\n\ndef handle_processing_complete(response):\n    print(f\"Processing complete: {response.payload}\")\n</code></pre>"},{"location":"protocols/a2a/#5-workflow-coordination","title":"5. Workflow Coordination","text":"<p>Multi-agent workflow coordination:</p> <pre><code># Define workflow\nworkflow = a2a.create_workflow(\n    name='order-fulfillment',\n    steps=[\n        {\n            'agent': 'inventory-agent',\n            'action': 'check_availability',\n            'input': '${order.items}'\n        },\n        {\n            'agent': 'payment-agent',\n            'action': 'process_payment',\n            'input': '${order.payment_info}',\n            'depends_on': ['check_availability']\n        },\n        {\n            'agent': 'shipping-agent',\n            'action': 'create_shipment',\n            'input': '${order.shipping_info}',\n            'depends_on': ['process_payment']\n        }\n    ]\n)\n\n# Execute workflow\nresult = a2a.execute_workflow(\n    workflow='order-fulfillment',\n    input={'order': order_data}\n)\n</code></pre>"},{"location":"protocols/a2a/#features","title":"Features","text":""},{"location":"protocols/a2a/#1-agent-discovery","title":"1. Agent Discovery","text":"<p>Dynamic agent discovery based on capabilities:</p> <pre><code># Find agents by capability\nagents = a2a.discover(\n    capability='image-processing',\n    filters={\n        'available': True,\n        'load': {'$lt': 0.8}\n    }\n)\n\n# Get agent details\nagent_info = a2a.get_agent_info('image-processing-agent')\nprint(f\"Capabilities: {agent_info.capabilities}\")\nprint(f\"Status: {agent_info.status}\")\nprint(f\"Load: {agent_info.current_load}\")\n</code></pre>"},{"location":"protocols/a2a/#2-load-balancing","title":"2. Load Balancing","text":"<p>Distribute work across multiple agent instances:</p> <pre><code># Configure load balancing\na2a.configure_load_balancing(\n    strategy='round-robin',  # or 'least-loaded', 'random'\n    health_check_interval=5000,\n    max_retries=3\n)\n\n# Send request (automatically load balanced)\nresponse = a2a.request(\n    to='data-processing-agent',  # Routes to best instance\n    action='process',\n    payload=data\n)\n</code></pre>"},{"location":"protocols/a2a/#3-message-persistence","title":"3. Message Persistence","text":"<p>Ensure message delivery with persistence:</p> <pre><code># Send persistent message\na2a.send_persistent(\n    to='critical-agent',\n    message=important_message,\n    ttl=3600000,  # 1 hour\n    retry_policy={\n        'max_attempts': 5,\n        'backoff': 'exponential'\n    }\n)\n</code></pre>"},{"location":"protocols/a2a/#4-circuit-breaker","title":"4. Circuit Breaker","text":"<p>Prevent cascading failures:</p> <pre><code># Configure circuit breaker\na2a.configure_circuit_breaker(\n    agent='external-api-agent',\n    failure_threshold=5,\n    timeout=30000,\n    reset_timeout=60000\n)\n\n# Requests will fail fast if circuit is open\ntry:\n    response = a2a.request(to='external-api-agent', ...)\nexcept CircuitBreakerOpenError:\n    # Use fallback\n    response = fallback_handler()\n</code></pre>"},{"location":"protocols/a2a/#5-message-tracing","title":"5. Message Tracing","text":"<p>Track messages across agents:</p> <pre><code># Enable tracing\na2a.enable_tracing(\n    trace_id='trace-123',\n    sample_rate=1.0\n)\n\n# Messages will include trace information\nresponse = a2a.request(\n    to='agent-b',\n    action='process',\n    payload=data\n)\n\n# View trace\ntrace = a2a.get_trace('trace-123')\nfor span in trace.spans:\n    print(f\"{span.agent_id}: {span.duration_ms}ms\")\n</code></pre>"},{"location":"protocols/a2a/#best-practices","title":"Best Practices","text":""},{"location":"protocols/a2a/#1-message-design","title":"1. Message Design","text":"<ul> <li>Keep messages small and focused</li> <li>Use correlation IDs for request tracking</li> <li>Include timeout values for time-sensitive operations</li> <li>Validate message payloads</li> </ul>"},{"location":"protocols/a2a/#2-error-handling","title":"2. Error Handling","text":"<pre><code>from a2a.exceptions import AgentNotFoundError, TimeoutError\n\ntry:\n    response = a2a.request(to='agent-x', ...)\nexcept AgentNotFoundError:\n    # Agent not available, use fallback\n    response = fallback_agent.process(...)\nexcept TimeoutError:\n    # Request timed out, retry or fail gracefully\n    logger.warning(\"Request timed out\")\n    response = None\n</code></pre>"},{"location":"protocols/a2a/#3-resource-management","title":"3. Resource Management","text":"<ul> <li>Implement backpressure mechanisms</li> <li>Set appropriate queue sizes</li> <li>Monitor agent load and scale accordingly</li> <li>Use circuit breakers for external dependencies</li> </ul>"},{"location":"protocols/a2a/#4-security","title":"4. Security","text":"<pre><code># Authenticate messages\na2a.configure_security(\n    authentication='jwt',\n    encryption='aes-256',\n    verify_sender=True\n)\n\n# Messages are automatically signed and encrypted\nresponse = a2a.request(to='secure-agent', ...)\n</code></pre>"},{"location":"protocols/a2a/#integration-with-ibm-orchestrate","title":"Integration with IBM Orchestrate","text":"<p>A2A integrates seamlessly with IBM Orchestrate:</p> <pre><code>from orchestrate import OrchestratePlatform\nfrom a2a import A2AClient\n\n# Initialize both\norchestrate = OrchestratePlatform(...)\na2a = A2AClient(...)\n\n# Register A2A as communication layer\norchestrate.register_communication_layer(\n    name='a2a',\n    layer=a2a\n)\n\n# Agents automatically use A2A for communication\nagent = orchestrate.create_agent(\n    name='my-agent',\n    communication='a2a'\n)\n</code></pre>"},{"location":"protocols/a2a/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"protocols/a2a/#message-metrics","title":"Message Metrics","text":"<pre><code># Get message statistics\nstats = a2a.get_statistics(\n    agent_id='my-agent',\n    period='last_hour'\n)\n\nprint(f\"Messages sent: {stats.messages_sent}\")\nprint(f\"Messages received: {stats.messages_received}\")\nprint(f\"Average latency: {stats.avg_latency_ms}ms\")\nprint(f\"Error rate: {stats.error_rate}%\")\n</code></pre>"},{"location":"protocols/a2a/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable debug logging\na2a.set_log_level('DEBUG')\n\n# Log all messages\na2a.enable_message_logging(\n    log_payloads=True,\n    log_metadata=True\n)\n</code></pre>"},{"location":"protocols/a2a/#resources","title":"Resources","text":"<ul> <li>A2A Specification</li> <li>API Reference</li> <li>MCP Protocol</li> <li>Architecture Overview</li> </ul>"},{"location":"protocols/mcp/","title":"Model Context Protocol (MCP)","text":""},{"location":"protocols/mcp/#overview","title":"Overview","text":"<p>The Model Context Protocol (MCP) is a standardized protocol that enables AI agents to interact with Large Language Models (LLMs) and other AI services in a consistent, efficient manner. MCP abstracts the complexities of different model providers and provides a unified interface for context management, model invocation, and response handling.</p>"},{"location":"protocols/mcp/#purpose","title":"Purpose","text":"<p>MCP addresses several key challenges in AI agent development:</p> <ul> <li>Provider Abstraction: Work with multiple LLM providers through a single interface</li> <li>Context Management: Maintain conversation history and relevant context</li> <li>State Persistence: Preserve context across multiple interactions</li> <li>Resource Optimization: Efficient token usage and caching</li> <li>Error Handling: Standardized error responses and retry mechanisms</li> </ul>"},{"location":"protocols/mcp/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Agent Layer\"\n        A1[Agent 1]\n        A2[Agent 2]\n        A3[Agent 3]\n    end\n\n    subgraph \"MCP Layer\"\n        MCP[MCP Interface]\n        CM[Context Manager]\n        MM[Model Manager]\n        TM[Token Manager]\n        CACHE[Response Cache]\n    end\n\n    subgraph \"Provider Layer\"\n        P1[OpenAI]\n        P2[Anthropic]\n        P3[IBM Watson]\n        P4[Azure OpenAI]\n        P5[Custom Models]\n    end\n\n    subgraph \"Storage\"\n        DB[(Context Store)]\n        VCTR[(Vector Store)]\n    end\n\n    A1 --&gt; MCP\n    A2 --&gt; MCP\n    A3 --&gt; MCP\n\n    MCP --&gt; CM\n    MCP --&gt; MM\n    MCP --&gt; TM\n    MCP --&gt; CACHE\n\n    CM --&gt; DB\n    CM --&gt; VCTR\n\n    MM --&gt; P1\n    MM --&gt; P2\n    MM --&gt; P3\n    MM --&gt; P4\n    MM --&gt; P5\n\n    TM --&gt; MM\n    CACHE --&gt; MM\n\n    style MCP fill:#24a148\n    style CM fill:#24a148\n    style MM fill:#24a148</code></pre>"},{"location":"protocols/mcp/#core-components","title":"Core Components","text":""},{"location":"protocols/mcp/#1-mcp-interface","title":"1. MCP Interface","text":"<p>The main entry point for agents to interact with AI models:</p> <pre><code>from mcp import MCPClient\n\n# Initialize MCP client\nmcp = MCPClient(\n    provider='openai',\n    model='gpt-4',\n    api_key=os.getenv('OPENAI_API_KEY')\n)\n\n# Send a request\nresponse = mcp.complete(\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ],\n    context_id='conversation-123',\n    temperature=0.7,\n    max_tokens=150\n)\n</code></pre>"},{"location":"protocols/mcp/#2-context-manager","title":"2. Context Manager","text":"<p>Manages conversation history and context:</p> <pre><code># Create a new context\ncontext = mcp.context.create(\n    context_id='conversation-123',\n    metadata={\n        'user_id': 'user-456',\n        'session_id': 'session-789'\n    }\n)\n\n# Add messages to context\nmcp.context.add_message(\n    context_id='conversation-123',\n    role='user',\n    content='Tell me about AI agents'\n)\n\n# Retrieve context\nhistory = mcp.context.get_history(\n    context_id='conversation-123',\n    limit=10\n)\n</code></pre>"},{"location":"protocols/mcp/#3-model-manager","title":"3. Model Manager","text":"<p>Handles model selection and invocation:</p> <pre><code># List available models\nmodels = mcp.models.list()\n\n# Get model capabilities\ncapabilities = mcp.models.get_capabilities('gpt-4')\n\n# Switch models dynamically\nmcp.models.set_default('claude-3-opus')\n</code></pre>"},{"location":"protocols/mcp/#4-token-manager","title":"4. Token Manager","text":"<p>Optimizes token usage and manages costs:</p> <pre><code># Estimate tokens before sending\ntoken_count = mcp.tokens.estimate(\n    messages=messages,\n    model='gpt-4'\n)\n\n# Get token usage statistics\nusage = mcp.tokens.get_usage(\n    context_id='conversation-123',\n    period='last_24h'\n)\n</code></pre>"},{"location":"protocols/mcp/#protocol-specification","title":"Protocol Specification","text":""},{"location":"protocols/mcp/#request-format","title":"Request Format","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"context_id\": \"conversation-123\",\n  \"model\": \"gpt-4\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are a helpful assistant.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"What is the capital of France?\"\n    }\n  ],\n  \"parameters\": {\n    \"temperature\": 0.7,\n    \"max_tokens\": 150,\n    \"top_p\": 1.0,\n    \"frequency_penalty\": 0.0,\n    \"presence_penalty\": 0.0\n  },\n  \"metadata\": {\n    \"user_id\": \"user-456\",\n    \"timestamp\": \"2026-01-15T11:42:00Z\"\n  }\n}\n</code></pre>"},{"location":"protocols/mcp/#response-format","title":"Response Format","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"context_id\": \"conversation-123\",\n  \"request_id\": \"req-abc123\",\n  \"model\": \"gpt-4\",\n  \"response\": {\n    \"role\": \"assistant\",\n    \"content\": \"The capital of France is Paris.\"\n  },\n  \"usage\": {\n    \"prompt_tokens\": 25,\n    \"completion_tokens\": 8,\n    \"total_tokens\": 33\n  },\n  \"metadata\": {\n    \"latency_ms\": 1250,\n    \"timestamp\": \"2026-01-15T11:42:01Z\"\n  }\n}\n</code></pre>"},{"location":"protocols/mcp/#error-format","title":"Error Format","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"context_id\": \"conversation-123\",\n  \"request_id\": \"req-abc123\",\n  \"error\": {\n    \"code\": \"RATE_LIMIT_EXCEEDED\",\n    \"message\": \"Rate limit exceeded. Please try again later.\",\n    \"retry_after\": 60,\n    \"details\": {\n      \"limit\": 100,\n      \"remaining\": 0,\n      \"reset_at\": \"2026-01-15T11:43:00Z\"\n    }\n  }\n}\n</code></pre>"},{"location":"protocols/mcp/#features","title":"Features","text":""},{"location":"protocols/mcp/#1-multi-provider-support","title":"1. Multi-Provider Support","text":"<p>Switch between providers seamlessly:</p> <pre><code># Use OpenAI\nresponse = mcp.complete(\n    provider='openai',\n    model='gpt-4',\n    messages=messages\n)\n\n# Use Anthropic\nresponse = mcp.complete(\n    provider='anthropic',\n    model='claude-3-opus',\n    messages=messages\n)\n\n# Use IBM Watson\nresponse = mcp.complete(\n    provider='ibm-watson',\n    model='granite-13b',\n    messages=messages\n)\n</code></pre>"},{"location":"protocols/mcp/#2-context-persistence","title":"2. Context Persistence","text":"<p>Maintain context across sessions:</p> <pre><code># Save context\nmcp.context.save(\n    context_id='conversation-123',\n    storage='persistent'\n)\n\n# Load context later\nmcp.context.load(\n    context_id='conversation-123'\n)\n\n# Resume conversation\nresponse = mcp.complete(\n    context_id='conversation-123',\n    messages=[{\"role\": \"user\", \"content\": \"Continue our discussion\"}]\n)\n</code></pre>"},{"location":"protocols/mcp/#3-streaming-responses","title":"3. Streaming Responses","text":"<p>Handle streaming for real-time responses:</p> <pre><code># Stream response\nfor chunk in mcp.stream(\n    messages=messages,\n    context_id='conversation-123'\n):\n    print(chunk.content, end='', flush=True)\n</code></pre>"},{"location":"protocols/mcp/#4-function-calling","title":"4. Function Calling","text":"<p>Enable agents to call functions:</p> <pre><code># Define functions\nfunctions = [\n    {\n        \"name\": \"get_weather\",\n        \"description\": \"Get current weather for a location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\"type\": \"string\"},\n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n            },\n            \"required\": [\"location\"]\n        }\n    }\n]\n\n# Request with functions\nresponse = mcp.complete(\n    messages=messages,\n    functions=functions,\n    context_id='conversation-123'\n)\n\n# Handle function call\nif response.function_call:\n    result = execute_function(\n        response.function_call.name,\n        response.function_call.arguments\n    )\n</code></pre>"},{"location":"protocols/mcp/#5-embeddings","title":"5. Embeddings","text":"<p>Generate embeddings for semantic search:</p> <pre><code># Generate embeddings\nembeddings = mcp.embeddings.create(\n    input=\"AI agents are autonomous software entities\",\n    model=\"text-embedding-ada-002\"\n)\n\n# Store in vector database\nmcp.embeddings.store(\n    embeddings=embeddings,\n    metadata={\"source\": \"documentation\"},\n    collection=\"knowledge-base\"\n)\n\n# Semantic search\nresults = mcp.embeddings.search(\n    query=\"What are AI agents?\",\n    collection=\"knowledge-base\",\n    limit=5\n)\n</code></pre>"},{"location":"protocols/mcp/#best-practices","title":"Best Practices","text":""},{"location":"protocols/mcp/#1-context-management","title":"1. Context Management","text":"<ul> <li>Keep context size manageable (&lt; 8K tokens for most models)</li> <li>Implement context summarization for long conversations</li> <li>Clear old contexts regularly to save storage</li> </ul>"},{"location":"protocols/mcp/#2-error-handling","title":"2. Error Handling","text":"<pre><code>from mcp.exceptions import RateLimitError, ModelError\n\ntry:\n    response = mcp.complete(messages=messages)\nexcept RateLimitError as e:\n    # Wait and retry\n    time.sleep(e.retry_after)\n    response = mcp.complete(messages=messages)\nexcept ModelError as e:\n    # Log error and use fallback\n    logger.error(f\"Model error: {e}\")\n    response = fallback_response()\n</code></pre>"},{"location":"protocols/mcp/#3-token-optimization","title":"3. Token Optimization","text":"<ul> <li>Use appropriate max_tokens limits</li> <li>Implement response caching for repeated queries</li> <li>Monitor token usage and costs</li> </ul>"},{"location":"protocols/mcp/#4-security","title":"4. Security","text":"<ul> <li>Never log API keys or sensitive data</li> <li>Validate and sanitize user inputs</li> <li>Implement rate limiting per user/session</li> </ul>"},{"location":"protocols/mcp/#integration-with-ibm-orchestrate","title":"Integration with IBM Orchestrate","text":"<p>MCP integrates seamlessly with IBM Orchestrate:</p> <pre><code>from orchestrate import OrchestratePlatform\nfrom mcp import MCPClient\n\n# Initialize both\norchestrate = OrchestratePlatform(...)\nmcp = MCPClient(...)\n\n# Register MCP as a service\norchestrate.register_service(\n    name='mcp-service',\n    service=mcp,\n    health_check=mcp.health_check\n)\n\n# Use in workflows\nworkflow = orchestrate.create_workflow(\n    name='ai-conversation',\n    steps=[\n        {\n            'name': 'process-input',\n            'service': 'mcp-service',\n            'method': 'complete',\n            'input': '${user.message}'\n        }\n    ]\n)\n</code></pre>"},{"location":"protocols/mcp/#resources","title":"Resources","text":"<ul> <li>MCP Specification</li> <li>API Reference</li> <li>A2A Protocol</li> <li>Architecture Overview</li> </ul>"},{"location":"rag/api-reference/","title":"API Reference","text":"<p>Complete reference for the MCP Server REST API.</p>"},{"location":"rag/api-reference/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\n</code></pre>"},{"location":"rag/api-reference/#authentication","title":"Authentication","text":"<p>Currently, the API does not require authentication. In production, implement appropriate authentication mechanisms (API keys, OAuth, etc.).</p>"},{"location":"rag/api-reference/#common-response-codes","title":"Common Response Codes","text":"Code Description 200 Success 400 Bad Request - Invalid parameters 404 Not Found - Endpoint or resource not found 422 Unprocessable Entity - Validation error 500 Internal Server Error 503 Service Unavailable - Dependencies unavailable"},{"location":"rag/api-reference/#endpoints","title":"Endpoints","text":""},{"location":"rag/api-reference/#root","title":"Root","text":"<p>Get server information.</p> <p>Request: <pre><code>GET /\n</code></pre></p> <p>Response: <pre><code>{\n  \"name\": \"MCP RAG Server\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Model Context Protocol server for RAG operations\"\n}\n</code></pre></p>"},{"location":"rag/api-reference/#health-check","title":"Health Check","text":"<p>Check the health status of the server and its dependencies.</p> <p>Request: <pre><code>GET /health\n</code></pre></p> <p>Response (Healthy): <pre><code>{\n  \"status\": \"healthy\",\n  \"components\": {\n    \"watsonx\": true,\n    \"milvus\": true\n  }\n}\n</code></pre></p> <p>Response (Unhealthy): <pre><code>{\n  \"status\": \"unhealthy\",\n  \"components\": {\n    \"watsonx\": true,\n    \"milvus\": false\n  }\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - All components healthy - <code>503 Service Unavailable</code> - One or more components unhealthy</p> <p>Example: <pre><code>curl http://localhost:8000/health\n</code></pre></p>"},{"location":"rag/api-reference/#list-tools","title":"List Tools","text":"<p>Get a list of all available MCP tools.</p> <p>Request: <pre><code>GET /tools\n</code></pre></p> <p>Response: <pre><code>{\n  \"tools\": [\n    {\n      \"name\": \"rag_query\",\n      \"description\": \"Query the RAG knowledge base with LLM generation\",\n      \"endpoint\": \"/tools/rag_query\",\n      \"method\": \"POST\"\n    },\n    {\n      \"name\": \"rag_search\",\n      \"description\": \"Semantic search without LLM generation\",\n      \"endpoint\": \"/tools/rag_search\",\n      \"method\": \"POST\"\n    },\n    {\n      \"name\": \"rag_index\",\n      \"description\": \"Index a single document\",\n      \"endpoint\": \"/tools/rag_index\",\n      \"method\": \"POST\"\n    },\n    {\n      \"name\": \"rag_index_directory\",\n      \"description\": \"Index all documents in a directory\",\n      \"endpoint\": \"/tools/rag_index_directory\",\n      \"method\": \"POST\"\n    },\n    {\n      \"name\": \"rag_stats\",\n      \"description\": \"Get knowledge base statistics\",\n      \"endpoint\": \"/tools/rag_stats\",\n      \"method\": \"GET\"\n    },\n    {\n      \"name\": \"rag_clear\",\n      \"description\": \"Clear the knowledge base\",\n      \"endpoint\": \"/tools/rag_clear\",\n      \"method\": \"DELETE\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"rag/api-reference/#rag-query","title":"RAG Query","text":"<p>Query the knowledge base and generate an answer using the LLM.</p> <p>Request: <pre><code>POST /tools/rag_query\nContent-Type: application/json\n</code></pre></p> <p>Request Body: <pre><code>{\n  \"query\": \"What is the A2A protocol?\",\n  \"top_k\": 5,\n  \"include_sources\": true\n}\n</code></pre></p> <p>Parameters:</p> Parameter Type Required Default Description <code>query</code> string Yes - The user's question or query <code>top_k</code> integer No 5 Number of context chunks to retrieve (1-20) <code>include_sources</code> boolean No true Include source information in response <p>Response: <pre><code>{\n  \"answer\": \"The Agent-to-Agent Protocol (A2A) is a standardized communication framework that enables autonomous agents to discover, communicate, and collaborate with each other...\",\n  \"context\": [\n    \"The Agent-to-Agent Protocol (A2A) enables seamless communication between autonomous agents...\",\n    \"A2A provides a standardized messaging framework for agent interactions...\"\n  ],\n  \"sources\": [\n    {\n      \"source\": \"data/documents/sample_doc.md\",\n      \"score\": 0.92,\n      \"chunk_id\": \"abc123...\"\n    },\n    {\n      \"source\": \"data/documents/sample_doc.md\",\n      \"score\": 0.89,\n      \"chunk_id\": \"def456...\"\n    }\n  ]\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - Query successful - <code>422 Unprocessable Entity</code> - Invalid parameters - <code>500 Internal Server Error</code> - Query failed</p> <p>Example: <pre><code>curl -X POST http://localhost:8000/tools/rag_query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"What is the A2A protocol?\",\n    \"top_k\": 5,\n    \"include_sources\": true\n  }'\n</code></pre></p>"},{"location":"rag/api-reference/#rag-search","title":"RAG Search","text":"<p>Perform semantic search without LLM generation.</p> <p>Request: <pre><code>POST /tools/rag_search\nContent-Type: application/json\n</code></pre></p> <p>Request Body: <pre><code>{\n  \"query\": \"agent communication\",\n  \"top_k\": 10\n}\n</code></pre></p> <p>Parameters:</p> Parameter Type Required Default Description <code>query</code> string Yes - Search query <code>top_k</code> integer No 5 Number of results to return (1-20) <p>Response: <pre><code>{\n  \"query\": \"agent communication\",\n  \"results\": [\n    {\n      \"id\": \"abc123...\",\n      \"text\": \"The Agent-to-Agent Protocol enables...\",\n      \"source\": \"data/documents/sample_doc.md\",\n      \"timestamp\": 1705420800,\n      \"score\": 0.89\n    },\n    {\n      \"id\": \"def456...\",\n      \"text\": \"Communication between agents uses...\",\n      \"source\": \"data/documents/sample_doc.md\",\n      \"timestamp\": 1705420800,\n      \"score\": 0.85\n    }\n  ],\n  \"count\": 10\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - Search successful - <code>422 Unprocessable Entity</code> - Invalid parameters - <code>500 Internal Server Error</code> - Search failed</p> <p>Example: <pre><code>curl -X POST http://localhost:8000/tools/rag_search \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"agent communication\",\n    \"top_k\": 10\n  }'\n</code></pre></p>"},{"location":"rag/api-reference/#index-document","title":"Index Document","text":"<p>Index a single document into the knowledge base.</p> <p>Request: <pre><code>POST /tools/rag_index\nContent-Type: application/json\n</code></pre></p> <p>Request Body: <pre><code>{\n  \"file_path\": \"data/documents/my_document.pdf\"\n}\n</code></pre></p> <p>Parameters:</p> Parameter Type Required Description <code>file_path</code> string Yes Path to the document file (relative to project root) <p>Supported Formats: - PDF (<code>.pdf</code>) - Word Documents (<code>.docx</code>) - Text Files (<code>.txt</code>) - Markdown (<code>.md</code>)</p> <p>Response: <pre><code>{\n  \"status\": \"success\",\n  \"message\": \"Document indexed successfully\",\n  \"chunks_indexed\": 42,\n  \"file_path\": \"data/documents/my_document.pdf\"\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - Indexing successful - <code>422 Unprocessable Entity</code> - Invalid file path or unsupported format - <code>500 Internal Server Error</code> - Indexing failed</p> <p>Example: <pre><code>curl -X POST http://localhost:8000/tools/rag_index \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"file_path\": \"data/documents/my_document.pdf\"\n  }'\n</code></pre></p>"},{"location":"rag/api-reference/#index-directory","title":"Index Directory","text":"<p>Index all documents in a directory.</p> <p>Request: <pre><code>POST /tools/rag_index_directory\nContent-Type: application/json\n</code></pre></p> <p>Request Body: <pre><code>{\n  \"directory_path\": \"data/documents\",\n  \"recursive\": true\n}\n</code></pre></p> <p>Parameters:</p> Parameter Type Required Default Description <code>directory_path</code> string Yes - Path to the directory <code>recursive</code> boolean No true Process subdirectories <p>Response: <pre><code>{\n  \"status\": \"success\",\n  \"message\": \"Directory indexed successfully\",\n  \"chunks_indexed\": 156,\n  \"directory_path\": \"data/documents\"\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - Indexing successful - <code>422 Unprocessable Entity</code> - Invalid directory path - <code>500 Internal Server Error</code> - Indexing failed</p> <p>Example: <pre><code>curl -X POST http://localhost:8000/tools/rag_index_directory \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"directory_path\": \"data/documents\",\n    \"recursive\": true\n  }'\n</code></pre></p>"},{"location":"rag/api-reference/#get-statistics","title":"Get Statistics","text":"<p>Get statistics about the knowledge base.</p> <p>Request: <pre><code>GET /tools/rag_stats\n</code></pre></p> <p>Response: <pre><code>{\n  \"status\": \"success\",\n  \"statistics\": {\n    \"collection_name\": \"rag_knowledge_base\",\n    \"num_entities\": 156,\n    \"metric_type\": \"COSINE\",\n    \"dimension\": 384\n  }\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - Statistics retrieved - <code>500 Internal Server Error</code> - Failed to retrieve statistics</p> <p>Example: <pre><code>curl http://localhost:8000/tools/rag_stats\n</code></pre></p>"},{"location":"rag/api-reference/#clear-knowledge-base","title":"Clear Knowledge Base","text":"<p>Clear all data from the knowledge base.</p> <p>\u26a0\ufe0f Warning: This operation is irreversible and will delete all indexed documents.</p> <p>Request: <pre><code>DELETE /tools/rag_clear\n</code></pre></p> <p>Response: <pre><code>{\n  \"status\": \"success\",\n  \"message\": \"Knowledge base cleared successfully\"\n}\n</code></pre></p> <p>Status Codes: - <code>200 OK</code> - Knowledge base cleared - <code>500 Internal Server Error</code> - Clear operation failed</p> <p>Example: <pre><code>curl -X DELETE http://localhost:8000/tools/rag_clear\n</code></pre></p>"},{"location":"rag/api-reference/#error-responses","title":"Error Responses","text":"<p>All endpoints may return error responses in the following format:</p> <pre><code>{\n  \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre>"},{"location":"rag/api-reference/#common-errors","title":"Common Errors","text":"<p>400 Bad Request: <pre><code>{\n  \"detail\": \"Invalid request parameters\"\n}\n</code></pre></p> <p>404 Not Found: <pre><code>{\n  \"detail\": \"Endpoint not found\"\n}\n</code></pre></p> <p>422 Unprocessable Entity: <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"query\"],\n      \"msg\": \"field required\",\n      \"type\": \"value_error.missing\"\n    }\n  ]\n}\n</code></pre></p> <p>500 Internal Server Error: <pre><code>{\n  \"detail\": \"Internal server error: [error details]\"\n}\n</code></pre></p> <p>503 Service Unavailable: <pre><code>{\n  \"detail\": \"Service dependencies unavailable\"\n}\n</code></pre></p>"},{"location":"rag/api-reference/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, no rate limiting is implemented. In production, consider implementing rate limiting to prevent abuse.</p>"},{"location":"rag/api-reference/#interactive-documentation","title":"Interactive Documentation","text":"<p>The server provides interactive API documentation:</p> <ul> <li>Swagger UI: <code>http://localhost:8000/docs</code></li> <li>ReDoc: <code>http://localhost:8000/redoc</code></li> </ul> <p>These interfaces allow you to: - Explore all endpoints - Test API calls directly from the browser - View request/response schemas - Download OpenAPI specification</p>"},{"location":"rag/api-reference/#client-libraries","title":"Client Libraries","text":""},{"location":"rag/api-reference/#python","title":"Python","text":"<pre><code>import httpx\nimport asyncio\n\nclass RAGClient:\n    def __init__(self, base_url: str = \"http://localhost:8000\"):\n        self.base_url = base_url\n        self.client = httpx.AsyncClient()\n\n    async def query(self, query: str, top_k: int = 5):\n        response = await self.client.post(\n            f\"{self.base_url}/tools/rag_query\",\n            json={\"query\": query, \"top_k\": top_k}\n        )\n        return response.json()\n\n    async def search(self, query: str, top_k: int = 5):\n        response = await self.client.post(\n            f\"{self.base_url}/tools/rag_search\",\n            json={\"query\": query, \"top_k\": top_k}\n        )\n        return response.json()\n\n    async def index(self, file_path: str):\n        response = await self.client.post(\n            f\"{self.base_url}/tools/rag_index\",\n            json={\"file_path\": file_path}\n        )\n        return response.json()\n\n    async def stats(self):\n        response = await self.client.get(\n            f\"{self.base_url}/tools/rag_stats\"\n        )\n        return response.json()\n\n    async def close(self):\n        await self.client.aclose()\n\n# Usage\nasync def main():\n    client = RAGClient()\n    result = await client.query(\"What is the A2A protocol?\")\n    print(result[\"answer\"])\n    await client.close()\n\nasyncio.run(main())\n</code></pre>"},{"location":"rag/api-reference/#javascripttypescript","title":"JavaScript/TypeScript","text":"<pre><code>class RAGClient {\n  constructor(private baseUrl: string = 'http://localhost:8000') {}\n\n  async query(query: string, topK: number = 5) {\n    const response = await fetch(`${this.baseUrl}/tools/rag_query`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ query, top_k: topK })\n    });\n    return await response.json();\n  }\n\n  async search(query: string, topK: number = 5) {\n    const response = await fetch(`${this.baseUrl}/tools/rag_search`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ query, top_k: topK })\n    });\n    return await response.json();\n  }\n\n  async index(filePath: string) {\n    const response = await fetch(`${this.baseUrl}/tools/rag_index`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ file_path: filePath })\n    });\n    return await response.json();\n  }\n\n  async stats() {\n    const response = await fetch(`${this.baseUrl}/tools/rag_stats`);\n    return await response.json();\n  }\n}\n\n// Usage\nconst client = new RAGClient();\nconst result = await client.query(\"What is the A2A protocol?\");\nconsole.log(result.answer);\n</code></pre>"},{"location":"rag/api-reference/#best-practices","title":"Best Practices","text":""},{"location":"rag/api-reference/#1-query-optimization","title":"1. Query Optimization","text":"<ul> <li>Use specific, well-formed questions</li> <li>Adjust <code>top_k</code> based on your needs (3-5 for focused, 10-20 for comprehensive)</li> <li>Enable <code>include_sources</code> for transparency</li> </ul>"},{"location":"rag/api-reference/#2-indexing","title":"2. Indexing","text":"<ul> <li>Index documents in batches using <code>rag_index_directory</code></li> <li>Use appropriate file formats (PDF, DOCX, TXT, MD)</li> <li>Ensure documents are well-structured and readable</li> </ul>"},{"location":"rag/api-reference/#3-search","title":"3. Search","text":"<ul> <li>Use <code>rag_search</code> for exploratory queries</li> <li>Use <code>rag_query</code> for question-answering</li> <li>Monitor similarity scores to tune thresholds</li> </ul>"},{"location":"rag/api-reference/#4-monitoring","title":"4. Monitoring","text":"<ul> <li>Regularly check <code>/health</code> endpoint</li> <li>Monitor <code>/tools/rag_stats</code> for collection size</li> <li>Track response times and error rates</li> </ul>"},{"location":"rag/api-reference/#see-also","title":"See Also","text":"<ul> <li>Quick Start Guide</li> <li>Configuration Guide</li> <li>Testing Guide</li> <li>Troubleshooting</li> </ul>"},{"location":"rag/configuration/","title":"Configuration Guide","text":"<p>Comprehensive configuration options for the A2A RAG Agent system.</p>"},{"location":"rag/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"rag/configuration/#primary-configuration","title":"Primary Configuration","text":"<p>File: <code>RAG/config/.env</code></p> <p>This file contains all environment variables for the system.</p>"},{"location":"rag/configuration/#settings-module","title":"Settings Module","text":"<p>File: <code>RAG/config/settings.py</code></p> <p>Pydantic-based settings management with validation and type safety.</p>"},{"location":"rag/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"rag/configuration/#watsonxai-configuration","title":"Watsonx.ai Configuration","text":"<pre><code># API Credentials (Required)\nWATSONX_API_KEY=your-api-key-here\nWATSONX_PROJECT_ID=your-project-id-here\nWATSONX_URL=https://us-south.ml.cloud.ibm.com\n\n# Embedding Model\nEMBEDDING_MODEL=ibm/granite-embedding-278m-multilingual\nEMBEDDING_DIMENSION=768\n\n# LLM Model\nLLM_MODEL=openai/gpt-oss-120b\nLLM_MAX_TOKENS=16384\nLLM_TEMPERATURE=0.7\n</code></pre> <p>Available Models:</p> Model Type Dimension Token Limit <code>ibm/granite-embedding-278m-multilingual</code> Embedding 768 512 <code>ibm/slate-125m-english-rtrvr-v2</code> Embedding 384 512 <code>openai/gpt-oss-120b</code> LLM - 16384 <code>ibm/granite-3-8b-instruct</code> LLM - 8192"},{"location":"rag/configuration/#milvus-configuration","title":"Milvus Configuration","text":"<pre><code># Connection\nMILVUS_HOST=localhost\nMILVUS_PORT=19530\nMILVUS_USER=\nMILVUS_PASSWORD=\n\n# Collection\nMILVUS_COLLECTION_NAME=rag_knowledge_base\nMILVUS_INDEX_TYPE=IVF_FLAT\nMILVUS_METRIC_TYPE=COSINE\nMILVUS_NLIST=128\n</code></pre> <p>Index Types:</p> Type Description Use Case <code>IVF_FLAT</code> Inverted file with flat search Balanced speed/accuracy <code>IVF_SQ8</code> IVF with scalar quantization Memory-efficient <code>HNSW</code> Hierarchical navigable small world High accuracy <code>FLAT</code> Brute force search Small datasets <p>Metric Types:</p> Type Description Range <code>COSINE</code> Cosine similarity [-1, 1] <code>L2</code> Euclidean distance [0, \u221e) <code>IP</code> Inner product (-\u221e, \u221e)"},{"location":"rag/configuration/#mcp-server-configuration","title":"MCP Server Configuration","text":"<pre><code># Server\nMCP_SERVER_HOST=0.0.0.0\nMCP_SERVER_PORT=8000\nMCP_SERVER_RELOAD=false\n\n# CORS\nMCP_CORS_ORIGINS=[\"*\"]\nMCP_CORS_ALLOW_CREDENTIALS=true\n</code></pre>"},{"location":"rag/configuration/#rag-configuration","title":"RAG Configuration","text":"<pre><code># Chunking\nRAG_CHUNK_SIZE=80           # words\nRAG_CHUNK_OVERLAP=10        # words\nRAG_MIN_CHUNK_SIZE=20       # words\n\n# Retrieval\nRAG_TOP_K=5                 # number of results\nRAG_SCORE_THRESHOLD=0.7     # similarity threshold\nRAG_MAX_CONTEXT_LENGTH=2000 # tokens\n\n# Generation\nRAG_SYSTEM_PROMPT=\"You are a helpful assistant...\"\nRAG_INCLUDE_SOURCES=true\n</code></pre>"},{"location":"rag/configuration/#logging-configuration","title":"Logging Configuration","text":"<pre><code># Logging\nLOG_LEVEL=INFO              # DEBUG, INFO, WARNING, ERROR\nLOG_FORMAT=json             # json or text\nLOG_FILE=logs/rag.log\nLOG_ROTATION=1 day\nLOG_RETENTION=30 days\n</code></pre>"},{"location":"rag/configuration/#configuration-tuning","title":"Configuration Tuning","text":""},{"location":"rag/configuration/#chunk-size-optimization","title":"Chunk Size Optimization","text":"<p>The chunk size affects both retrieval quality and token limits.</p> <p>Guidelines:</p> <pre><code># Technical documentation (dense information)\nRAG_CHUNK_SIZE=60-100  # words\n\n# Narrative content (stories, articles)\nRAG_CHUNK_SIZE=100-150  # words\n\n# Code documentation\nRAG_CHUNK_SIZE=50-80  # words\n\n# Legal/policy documents\nRAG_CHUNK_SIZE=80-120  # words\n</code></pre> <p>Considerations: - Embedding model token limit (512 tokens for granite-embedding-278m) - Context window of LLM (16384 tokens for gpt-oss-120b) - Document structure and formatting - Query complexity - Word-to-token ratio (approximately 1.3 tokens per word)</p>"},{"location":"rag/configuration/#chunk-overlap","title":"Chunk Overlap","text":"<p>Overlap ensures context continuity across chunks.</p> <pre><code># Standard overlap (recommended)\nRAG_CHUNK_OVERLAP=10  # ~12.5% of 80-word chunks\n\n# High overlap (better context, more storage)\nRAG_CHUNK_OVERLAP=20  # ~25% of 80-word chunks\n\n# Low overlap (less storage, potential context loss)\nRAG_CHUNK_OVERLAP=5  # ~6% of 80-word chunks\n</code></pre>"},{"location":"rag/configuration/#top-k-selection","title":"Top-K Selection","text":"<p>Number of chunks to retrieve for context.</p> <pre><code># Focused queries (specific questions)\nRAG_TOP_K=3-5\n\n# Exploratory queries (broad topics)\nRAG_TOP_K=10-15\n\n# Comprehensive analysis\nRAG_TOP_K=15-20\n</code></pre> <p>Trade-offs: - Higher K: More context, slower, more tokens - Lower K: Faster, less context, may miss relevant info</p>"},{"location":"rag/configuration/#score-threshold","title":"Score Threshold","text":"<p>Minimum similarity score for retrieved chunks.</p> <pre><code># High precision (strict matching)\nRAG_SCORE_THRESHOLD=0.85\n\n# Balanced (recommended)\nRAG_SCORE_THRESHOLD=0.70\n\n# High recall (include more results)\nRAG_SCORE_THRESHOLD=0.60\n</code></pre>"},{"location":"rag/configuration/#llm-parameters","title":"LLM Parameters","text":"<pre><code># Temperature (creativity vs consistency)\nLLM_TEMPERATURE=0.7  # Balanced\n# 0.0-0.3: Deterministic, factual\n# 0.4-0.7: Balanced\n# 0.8-1.0: Creative, varied\n\n# Max tokens (response length)\nLLM_MAX_TOKENS=16384  # Maximum for gpt-oss-120b\n# 512: Brief responses\n# 1024: Standard responses\n# 4096: Detailed responses\n# 16384: Comprehensive responses\n\n# Top P (nucleus sampling)\nLLM_TOP_P=0.9\n# 0.9: Balanced diversity\n# 0.95: More diverse\n# 0.8: More focused\n</code></pre>"},{"location":"rag/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"rag/configuration/#milvus-optimization","title":"Milvus Optimization","text":"<pre><code># For large collections (&gt;1M vectors)\nMILVUS_INDEX_TYPE=IVF_SQ8\nMILVUS_NLIST=1024\nMILVUS_NPROBE=16\n\n# For small collections (&lt;100K vectors)\nMILVUS_INDEX_TYPE=HNSW\nMILVUS_M=16\nMILVUS_EF_CONSTRUCTION=200\n\n# For memory-constrained environments\nMILVUS_INDEX_TYPE=IVF_SQ8\nMILVUS_NLIST=256\n</code></pre>"},{"location":"rag/configuration/#concurrent-processing","title":"Concurrent Processing","text":"<pre><code># Document processing\nMAX_CONCURRENT_DOCUMENTS=5\nBATCH_SIZE=100\n\n# Embedding generation\nEMBEDDING_BATCH_SIZE=32\nMAX_EMBEDDING_RETRIES=3\n\n# Query processing\nMAX_CONCURRENT_QUERIES=10\nQUERY_TIMEOUT=30  # seconds\n</code></pre>"},{"location":"rag/configuration/#caching","title":"Caching","text":"<pre><code># Enable caching\nENABLE_EMBEDDING_CACHE=true\nCACHE_TTL=3600  # seconds\nCACHE_MAX_SIZE=1000  # entries\n\n# Redis cache (optional)\nREDIS_HOST=localhost\nREDIS_PORT=6379\nREDIS_DB=0\n</code></pre>"},{"location":"rag/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"rag/configuration/#api-authentication","title":"API Authentication","text":"<pre><code># Enable authentication\nENABLE_AUTH=true\nAUTH_TYPE=api_key  # api_key, oauth, jwt\n\n# API Key authentication\nAPI_KEY_HEADER=X-API-Key\nAPI_KEYS=[\"key1\", \"key2\"]\n\n# JWT authentication\nJWT_SECRET=your-secret-key\nJWT_ALGORITHM=HS256\nJWT_EXPIRATION=3600\n</code></pre>"},{"location":"rag/configuration/#cors-configuration","title":"CORS Configuration","text":"<pre><code># Production CORS\nMCP_CORS_ORIGINS=[\"https://yourdomain.com\"]\nMCP_CORS_ALLOW_CREDENTIALS=true\nMCP_CORS_ALLOW_METHODS=[\"GET\", \"POST\", \"DELETE\"]\nMCP_CORS_ALLOW_HEADERS=[\"Content-Type\", \"Authorization\"]\n\n# Development CORS (permissive)\nMCP_CORS_ORIGINS=[\"*\"]\n</code></pre>"},{"location":"rag/configuration/#rate-limiting","title":"Rate Limiting","text":"<pre><code># Enable rate limiting\nENABLE_RATE_LIMIT=true\nRATE_LIMIT_REQUESTS=100\nRATE_LIMIT_PERIOD=60  # seconds\n\n# Per-endpoint limits\nQUERY_RATE_LIMIT=20\nINDEX_RATE_LIMIT=10\n</code></pre>"},{"location":"rag/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"rag/configuration/#development","title":"Development","text":"<pre><code># .env.development\nLOG_LEVEL=DEBUG\nMCP_SERVER_RELOAD=true\nENABLE_AUTH=false\nMCP_CORS_ORIGINS=[\"*\"]\nWATSONX_LLM_TEMPERATURE=0.7\n</code></pre>"},{"location":"rag/configuration/#staging","title":"Staging","text":"<pre><code># .env.staging\nLOG_LEVEL=INFO\nMCP_SERVER_RELOAD=false\nENABLE_AUTH=true\nMCP_CORS_ORIGINS=[\"https://staging.yourdomain.com\"]\nWATSONX_LLM_TEMPERATURE=0.5\n</code></pre>"},{"location":"rag/configuration/#production","title":"Production","text":"<pre><code># .env.production\nLOG_LEVEL=WARNING\nMCP_SERVER_RELOAD=false\nENABLE_AUTH=true\nENABLE_RATE_LIMIT=true\nMCP_CORS_ORIGINS=[\"https://yourdomain.com\"]\nWATSONX_LLM_TEMPERATURE=0.3\nENABLE_EMBEDDING_CACHE=true\n</code></pre>"},{"location":"rag/configuration/#configuration-validation","title":"Configuration Validation","text":""},{"location":"rag/configuration/#using-settings-module","title":"Using Settings Module","text":"<pre><code>from config.settings import get_settings\n\n# Load and validate settings\nsettings = get_settings()\n\n# Access settings\nprint(f\"Embedding model: {settings.watsonx_embedding_model}\")\nprint(f\"Chunk size: {settings.rag_chunk_size}\")\nprint(f\"Top K: {settings.rag_top_k}\")\n\n# Validate configuration\nassert settings.embedding_dimension == 384\nassert settings.rag_chunk_size &lt;= 512\n</code></pre>"},{"location":"rag/configuration/#configuration-checks","title":"Configuration Checks","text":"<pre><code># Verify configuration\ncd RAG\npython -c \"\nfrom config.settings import get_settings\nsettings = get_settings()\nprint('Configuration valid!')\nprint(f'Embedding model: {settings.watsonx_embedding_model}')\nprint(f'Milvus host: {settings.milvus_host}')\n\"\n</code></pre>"},{"location":"rag/configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"rag/configuration/#common-issues","title":"Common Issues","text":"<p>Issue: Token limit exceeded</p> <pre><code># Solution: Reduce chunk size\nRAG_CHUNK_SIZE=200  # Reduced from 300\n</code></pre> <p>Issue: Low retrieval quality</p> <pre><code># Solution: Adjust threshold and top-k\nRAG_SCORE_THRESHOLD=0.65  # Lowered from 0.7\nRAG_TOP_K=10  # Increased from 5\n</code></pre> <p>Issue: Slow query responses</p> <pre><code># Solution: Optimize Milvus and reduce top-k\nMILVUS_INDEX_TYPE=IVF_SQ8\nRAG_TOP_K=3  # Reduced from 5\nWATSONX_LLM_MAX_TOKENS=256  # Reduced from 512\n</code></pre> <p>Issue: High memory usage</p> <pre><code># Solution: Use quantized index and reduce batch size\nMILVUS_INDEX_TYPE=IVF_SQ8\nEMBEDDING_BATCH_SIZE=16  # Reduced from 32\n</code></pre>"},{"location":"rag/configuration/#configuration-templates","title":"Configuration Templates","text":""},{"location":"rag/configuration/#minimal-configuration","title":"Minimal Configuration","text":"<pre><code># Minimal .env for quick start\nWATSONX_API_KEY=your-key\nWATSONX_PROJECT_ID=your-project\nEMBEDDING_MODEL=ibm/granite-embedding-278m-multilingual\nLLM_MODEL=openai/gpt-oss-120b\n</code></pre>"},{"location":"rag/configuration/#production-configuration","title":"Production Configuration","text":"<pre><code># Production .env with all optimizations\nWATSONX_API_KEY=your-key\nWATSONX_PROJECT_ID=your-project\nWATSONX_URL=https://us-south.ml.cloud.ibm.com\nEMBEDDING_MODEL=ibm/granite-embedding-278m-multilingual\nEMBEDDING_DIMENSION=768\nLLM_MODEL=openai/gpt-oss-120b\nLLM_MAX_TOKENS=16384\nLLM_TEMPERATURE=0.3\n\nMILVUS_HOST=milvus-prod.internal\nMILVUS_PORT=19530\nMILVUS_COLLECTION_NAME=rag_production\nMILVUS_INDEX_TYPE=IVF_SQ8\nMILVUS_METRIC_TYPE=COSINE\n\nMCP_SERVER_HOST=0.0.0.0\nMCP_SERVER_PORT=8000\nMCP_CORS_ORIGINS=[\"https://yourdomain.com\"]\n\nRAG_CHUNK_SIZE=80\nRAG_CHUNK_OVERLAP=10\nRAG_TOP_K=5\nRAG_SCORE_THRESHOLD=0.7\n\nLOG_LEVEL=WARNING\nENABLE_AUTH=true\nENABLE_RATE_LIMIT=true\nENABLE_EMBEDDING_CACHE=true\n</code></pre>"},{"location":"rag/configuration/#see-also","title":"See Also","text":"<ul> <li>Quick Start Guide</li> <li>API Reference</li> <li>Testing Guide</li> <li>Troubleshooting</li> </ul>"},{"location":"rag/overview/","title":"A2A RAG Agent Overview","text":"<p>The A2A RAG Agent is a production-ready Retrieval-Augmented Generation system that combines the Agent-to-Agent (A2A) protocol with Model Context Protocol (MCP) tools to provide intelligent query services over a knowledge base.</p>"},{"location":"rag/overview/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    User[User/Client] --&gt; Agent[A2A RAG Agent&lt;br/&gt;LangGraph Workflow]\n    Agent --&gt; MCP[MCP Server&lt;br/&gt;FastAPI]\n    MCP --&gt; Watsonx[Watsonx.ai&lt;br/&gt;Embeddings + LLM]\n    MCP --&gt; Milvus[Milvus&lt;br/&gt;Vector Database]\n\n    style Agent fill:#e1f5ff\n    style MCP fill:#fff4e1\n    style Watsonx fill:#f0e1ff\n    style Milvus fill:#e1ffe1</code></pre>"},{"location":"rag/overview/#key-components","title":"Key Components","text":""},{"location":"rag/overview/#1-a2a-agent-langgraph","title":"1. A2A Agent (LangGraph)","text":"<ul> <li>Purpose: Orchestrates RAG workflows using state machine patterns</li> <li>Technology: LangGraph for workflow management</li> <li>Features:</li> <li>Asynchronous processing</li> <li>Error handling and retry logic</li> <li>A2A protocol message handling</li> <li>Conversation history management</li> </ul>"},{"location":"rag/overview/#2-mcp-server-fastapi","title":"2. MCP Server (FastAPI)","text":"<ul> <li>Purpose: Exposes RAG operations as RESTful API endpoints</li> <li>Technology: FastAPI with Pydantic validation</li> <li>Endpoints:</li> <li><code>/tools/rag_query</code> - Query with LLM generation</li> <li><code>/tools/rag_search</code> - Semantic search only</li> <li><code>/tools/rag_index</code> - Index documents</li> <li><code>/tools/rag_stats</code> - Knowledge base statistics</li> <li><code>/health</code> - Health check</li> </ul>"},{"location":"rag/overview/#3-watsonxai-integration","title":"3. Watsonx.ai Integration","text":"<ul> <li>Purpose: Provides AI capabilities</li> <li>Models:</li> <li>Embeddings: <code>ibm/granite-embedding-278m-multilingual</code> (768 dimensions)</li> <li>LLM: <code>openai/gpt-oss-120b</code> (16384 max tokens)</li> <li>Features:</li> <li>Multilingual semantic embeddings</li> <li>Context-aware response generation</li> <li>Retry logic with exponential backoff</li> </ul>"},{"location":"rag/overview/#4-milvus-vector-store","title":"4. Milvus Vector Store","text":"<ul> <li>Purpose: High-performance vector similarity search</li> <li>Configuration:</li> <li>Metric: COSINE similarity</li> <li>Index: IVF_FLAT</li> <li>Dimension: 768 (matches embedding model)</li> <li>Deployment: Podman/Docker containerized</li> </ul>"},{"location":"rag/overview/#rag-pipeline-flow","title":"RAG Pipeline Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Agent as A2A Agent\n    participant MCP as MCP Server\n    participant Watsonx as Watsonx.ai\n    participant Milvus as Milvus DB\n\n    User-&gt;&gt;Agent: Query\n    Agent-&gt;&gt;MCP: rag_query(query)\n    MCP-&gt;&gt;Watsonx: Generate embedding\n    Watsonx--&gt;&gt;MCP: Query vector\n    MCP-&gt;&gt;Milvus: Search similar vectors\n    Milvus--&gt;&gt;MCP: Top-K results\n    MCP-&gt;&gt;Watsonx: Generate answer with context\n    Watsonx--&gt;&gt;MCP: Generated response\n    MCP--&gt;&gt;Agent: Answer + sources\n    Agent--&gt;&gt;User: Response</code></pre>"},{"location":"rag/overview/#features","title":"Features","text":""},{"location":"rag/overview/#document-processing","title":"Document Processing","text":"<ul> <li>Supported Formats: PDF, DOCX, TXT, Markdown</li> <li>Chunking Strategy: </li> <li>Configurable chunk size (default: 300 tokens)</li> <li>Overlap for context preservation (default: 40 tokens)</li> <li>Metadata: Source tracking, chunk indexing, timestamps</li> </ul>"},{"location":"rag/overview/#semantic-search","title":"Semantic Search","text":"<ul> <li>Vector Similarity: COSINE metric for relevance</li> <li>Configurable Top-K: Retrieve 1-20 most relevant chunks</li> <li>Score Threshold: Filter low-relevance results (default: 0.7)</li> </ul>"},{"location":"rag/overview/#response-generation","title":"Response Generation","text":"<ul> <li>Context-Aware: Uses retrieved chunks as context</li> <li>Source Attribution: Includes source documents and scores</li> <li>Streaming Support: Real-time response generation</li> </ul>"},{"location":"rag/overview/#performance-characteristics","title":"Performance Characteristics","text":"Metric Value Notes Document Indexing ~0.37s for 196K lines Shakespeare complete works Query Response Time &lt; 5 seconds Including LLM generation Concurrent Queries 10+ simultaneous Tested with async handling Vector Search &lt; 1 second Average search time Memory Usage &lt; 2GB For typical workloads"},{"location":"rag/overview/#use-cases","title":"Use Cases","text":""},{"location":"rag/overview/#1-technical-documentation-qa","title":"1. Technical Documentation Q&amp;A","text":"<ul> <li>Index product documentation, API references, user guides</li> <li>Answer technical questions with source citations</li> <li>Maintain up-to-date knowledge base</li> </ul>"},{"location":"rag/overview/#2-knowledge-management","title":"2. Knowledge Management","text":"<ul> <li>Corporate knowledge bases</li> <li>Research paper repositories</li> <li>Policy and procedure documents</li> </ul>"},{"location":"rag/overview/#3-customer-support","title":"3. Customer Support","text":"<ul> <li>FAQ automation</li> <li>Ticket resolution assistance</li> <li>Product information retrieval</li> </ul>"},{"location":"rag/overview/#4-content-discovery","title":"4. Content Discovery","text":"<ul> <li>Semantic search across large document collections</li> <li>Related content recommendations</li> <li>Topic exploration</li> </ul>"},{"location":"rag/overview/#getting-started","title":"Getting Started","text":"<p>See the Quick Start Guide for installation and setup instructions.</p> <p>For detailed API documentation, see API Reference.</p> <p>For testing information, see Testing Guide.</p>"},{"location":"rag/quickstart/","title":"Quick Start Guide","text":"<p>Get the A2A RAG Agent up and running in minutes.</p>"},{"location":"rag/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11-3.13 (required for Watsonx.ai 1.5.0)</li> <li>Podman or Docker</li> <li>IBM Watsonx.ai account with API key and project ID</li> </ul>"},{"location":"rag/quickstart/#installation","title":"Installation","text":""},{"location":"rag/quickstart/#1-clone-and-navigate","title":"1. Clone and Navigate","text":"<pre><code>cd RAG\n</code></pre>"},{"location":"rag/quickstart/#2-run-setup-script","title":"2. Run Setup Script","text":"<pre><code>./deployment/setup.sh\n</code></pre> <p>This script will: - Check Python and Podman installation - Create a virtual environment - Install dependencies - Start Milvus with Podman - Create necessary directories</p>"},{"location":"rag/quickstart/#3-configure-credentials","title":"3. Configure Credentials","text":"<p>Edit <code>config/.env</code>:</p> <pre><code># Watsonx.ai Configuration\nWATSONX_API_KEY=your-api-key-here\nWATSONX_PROJECT_ID=your-project-id-here\nWATSONX_URL=https://us-south.ml.cloud.ibm.com\n\n# Embedding Model (768 dimensions)\nEMBEDDING_MODEL=ibm/granite-embedding-278m-multilingual\nEMBEDDING_DIMENSION=768\n\n# LLM Model\nLLM_MODEL=openai/gpt-oss-120b\nLLM_MAX_TOKENS=16384\n\n# Chunking Configuration\nRAG_CHUNK_SIZE=80  # words\nRAG_CHUNK_OVERLAP=10  # words\n</code></pre>"},{"location":"rag/quickstart/#starting-services","title":"Starting Services","text":""},{"location":"rag/quickstart/#option-1-using-the-start-script-recommended","title":"Option 1: Using the Start Script (Recommended)","text":"<pre><code>cd RAG\n./scripts/start_services.sh\n</code></pre> <p>This will: 1. Start Milvus vector database 2. Start MCP server on port 8000 3. Verify all services are healthy</p>"},{"location":"rag/quickstart/#option-2-manual-start","title":"Option 2: Manual Start","text":"<pre><code># Terminal 1: Start Milvus\ncd RAG/deployment\npodman-compose up -d\n\n# Terminal 2: Start MCP Server\ncd RAG\nsource venv/bin/activate\npython -m uvicorn mcp_server.server:app --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"rag/quickstart/#verify-installation","title":"Verify Installation","text":""},{"location":"rag/quickstart/#check-service-health","title":"Check Service Health","text":"<pre><code># Check MCP server\ncurl http://localhost:8000/health\n\n# Expected response:\n# {\n#   \"status\": \"healthy\",\n#   \"components\": {\n#     \"watsonx\": true,\n#     \"milvus\": true\n#   }\n# }\n</code></pre>"},{"location":"rag/quickstart/#list-available-tools","title":"List Available Tools","text":"<pre><code>curl http://localhost:8000/tools\n</code></pre>"},{"location":"rag/quickstart/#index-your-first-document","title":"Index Your First Document","text":""},{"location":"rag/quickstart/#1-add-documents","title":"1. Add Documents","text":"<p>Place your documents in <code>data/documents/</code>:</p> <pre><code>cp your-document.pdf RAG/data/documents/\n</code></pre> <p>Supported formats: PDF, DOCX, TXT, Markdown</p>"},{"location":"rag/quickstart/#2-index-the-document","title":"2. Index the Document","text":"<pre><code>curl -X POST http://localhost:8000/tools/rag_index \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"file_path\": \"data/documents/your-document.pdf\"\n  }'\n</code></pre> <p>Or index an entire directory:</p> <pre><code>curl -X POST http://localhost:8000/tools/rag_index_directory \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"directory_path\": \"data/documents\",\n    \"recursive\": true\n  }'\n</code></pre>"},{"location":"rag/quickstart/#3-verify-indexing","title":"3. Verify Indexing","text":"<pre><code>curl http://localhost:8000/tools/rag_stats\n</code></pre> <p>Expected response: <pre><code>{\n  \"status\": \"success\",\n  \"statistics\": {\n    \"collection_name\": \"rag_knowledge_base\",\n    \"num_entities\": 156,\n    \"metric_type\": \"COSINE\",\n    \"dimension\": 384\n  }\n}\n</code></pre></p>"},{"location":"rag/quickstart/#query-the-knowledge-base","title":"Query the Knowledge Base","text":""},{"location":"rag/quickstart/#simple-query","title":"Simple Query","text":"<pre><code>curl -X POST http://localhost:8000/tools/rag_query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"What is the A2A protocol?\",\n    \"top_k\": 5,\n    \"include_sources\": true\n  }'\n</code></pre>"},{"location":"rag/quickstart/#using-python","title":"Using Python","text":"<pre><code>import httpx\nimport asyncio\n\nasync def query_rag(query: str):\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://localhost:8000/tools/rag_query\",\n            json={\n                \"query\": query,\n                \"top_k\": 5,\n                \"include_sources\": True\n            }\n        )\n        return response.json()\n\n# Usage\nresult = asyncio.run(query_rag(\"What is the A2A protocol?\"))\nprint(result[\"answer\"])\n</code></pre>"},{"location":"rag/quickstart/#using-the-a2a-agent","title":"Using the A2A Agent","text":"<pre><code>from agent.a2a_agent import A2ARAGAgent\nfrom config.settings import get_settings\n\nasync def main():\n    settings = get_settings()\n    agent = A2ARAGAgent(settings)\n\n    # Process query\n    result = await agent.process_query(\"What is the A2A protocol?\")\n    print(result[\"response\"])\n\n    # Cleanup\n    await agent.close()\n\nasyncio.run(main())\n</code></pre>"},{"location":"rag/quickstart/#running-tests","title":"Running Tests","text":""},{"location":"rag/quickstart/#quick-test-core-tests","title":"Quick Test (Core Tests)","text":"<pre><code>cd RAG\n./scripts/run_tests.sh\n</code></pre>"},{"location":"rag/quickstart/#comprehensive-tests","title":"Comprehensive Tests","text":"<pre><code>cd RAG\nsource venv/bin/activate\npython -m pytest tests/ -v\n</code></pre>"},{"location":"rag/quickstart/#test-specific-components","title":"Test Specific Components","text":"<pre><code># A2A and MCP integration tests\npython -m pytest tests/ -v -k \"a2a or mcp\"\n\n# Document processor tests\npython -m pytest tests/test_document_processor.py -v\n\n# End-to-end tests\npython -m pytest tests/test_e2e_shakespeare.py -v\n</code></pre>"},{"location":"rag/quickstart/#stopping-services","title":"Stopping Services","text":"<pre><code>cd RAG\n./scripts/stop_services.sh\n</code></pre> <p>Or manually:</p> <pre><code># Stop MCP server (Ctrl+C in the terminal)\n\n# Stop Milvus\ncd RAG/deployment\npodman-compose down\n</code></pre>"},{"location":"rag/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>API Reference - Detailed API documentation</li> <li>Configuration Guide - Advanced configuration options</li> <li>Testing Guide - Comprehensive testing information</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"rag/quickstart/#example-workflows","title":"Example Workflows","text":""},{"location":"rag/quickstart/#workflow-1-technical-documentation","title":"Workflow 1: Technical Documentation","text":"<pre><code># 1. Index documentation\ncurl -X POST http://localhost:8000/tools/rag_index_directory \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"directory_path\": \"data/documents/tech-docs\"}'\n\n# 2. Query\ncurl -X POST http://localhost:8000/tools/rag_query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"How do I configure the API?\"}'\n</code></pre>"},{"location":"rag/quickstart/#workflow-2-research-papers","title":"Workflow 2: Research Papers","text":"<pre><code># 1. Index papers\ncurl -X POST http://localhost:8000/tools/rag_index_directory \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"directory_path\": \"data/documents/papers\"}'\n\n# 2. Search for related content\ncurl -X POST http://localhost:8000/tools/rag_search \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"query\": \"machine learning optimization\", \"top_k\": 10}'\n</code></pre>"},{"location":"rag/quickstart/#tips-for-success","title":"Tips for Success","text":"<ol> <li>Chunk Size: Adjust <code>RAG_CHUNK_SIZE</code> based on your content</li> <li>Technical docs: 200-300 tokens</li> <li> <p>Narrative content: 400-500 tokens</p> </li> <li> <p>Top-K: Balance between precision and recall</p> </li> <li>Focused queries: 3-5 results</li> <li> <p>Exploratory queries: 10-20 results</p> </li> <li> <p>Score Threshold: Filter irrelevant results</p> </li> <li>High precision: 0.8-0.9</li> <li> <p>High recall: 0.6-0.7</p> </li> <li> <p>Model Selection: Choose appropriate models</p> </li> <li>Embeddings: Match dimension to your needs</li> <li>LLM: Balance between speed and quality</li> </ol>"},{"location":"rag/testing/","title":"Testing Guide","text":"<p>Comprehensive testing information for the A2A RAG Agent system.</p>"},{"location":"rag/testing/#test-overview","title":"Test Overview","text":"<p>The RAG system includes multiple test layers:</p> <ul> <li>Unit Tests: Individual component testing</li> <li>Integration Tests: Component interaction testing</li> <li>End-to-End Tests: Full pipeline testing</li> <li>Performance Tests: Load and scalability testing</li> </ul>"},{"location":"rag/testing/#test-results-summary","title":"Test Results Summary","text":"<p>Latest Test Run: 2026-01-19</p> Test Category Tests Passed Status A2A Agent 1 1 \u2705 100% MCP Server Integration 18 18 \u2705 100% MCP Tool Client 15 15 \u2705 100% Total 34 34 \u2705 100%"},{"location":"rag/testing/#quick-start","title":"Quick Start","text":""},{"location":"rag/testing/#run-all-tests","title":"Run All Tests","text":"<pre><code>cd RAG\n./scripts/run_tests.sh\n</code></pre>"},{"location":"rag/testing/#run-specific-test-categories","title":"Run Specific Test Categories","text":"<pre><code># A2A and MCP tests only\npython -m pytest tests/ -v -k \"a2a or mcp\"\n\n# Unit tests only\npython -m pytest tests/ -v -m unit\n\n# Integration tests only\npython -m pytest tests/ -v -m integration\n\n# End-to-end tests\npython -m pytest tests/ -v -m e2e\n</code></pre>"},{"location":"rag/testing/#test-infrastructure","title":"Test Infrastructure","text":""},{"location":"rag/testing/#services-required","title":"Services Required","text":"<p>Before running tests, ensure services are running:</p> <pre><code># Start all services\n./scripts/start_services.sh\n\n# Verify services\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"rag/testing/#test-configuration","title":"Test Configuration","text":"<p>Tests use <code>pytest.ini</code> for configuration:</p> <pre><code>[pytest]\ntestpaths = tests\npython_files = test_*.py\nmarkers =\n    unit: Unit tests\n    integration: Integration tests\n    e2e: End-to-end tests\n    slow: Slow running tests\nlog_cli = true\nlog_cli_level = INFO\n</code></pre>"},{"location":"rag/testing/#test-categories","title":"Test Categories","text":""},{"location":"rag/testing/#1-a2a-agent-tests","title":"1. A2A Agent Tests","text":"<p>Location: <code>tests/test_a2a_agent.py</code></p> <p>Coverage: - Agent initialization - A2A message handling - Query processing through workflow - Health checks - Capabilities reporting</p> <p>Example Test: <pre><code>async def test_agent_a2a_message():\n    \"\"\"Test A2A agent handles messages correctly.\"\"\"\n    agent = A2ARAGAgent(settings)\n\n    # Create A2A message\n    message = {\n        \"agent_id\": \"test-agent\",\n        \"message_type\": \"query\",\n        \"content\": \"What is the A2A protocol?\",\n        \"correlation_id\": \"test-123\"\n    }\n\n    # Process message\n    response = await agent.handle_a2a_message(message)\n\n    # Verify response\n    assert response[\"message_type\"] == \"response\"\n    assert \"content\" in response\n    assert response[\"correlation_id\"] == \"test-123\"\n</code></pre></p> <p>Run: <pre><code>python -m pytest tests/ -v -k \"agent\"\n</code></pre></p>"},{"location":"rag/testing/#2-mcp-server-integration-tests","title":"2. MCP Server Integration Tests","text":"<p>Location: <code>tests/test_mcp_server_integration.py</code></p> <p>Coverage: - Health endpoint functionality - RAG query endpoint - RAG search endpoint - RAG index endpoint - RAG stats endpoint - Error handling (404, 422, 405) - CORS support - Performance characteristics</p> <p>Example Test: <pre><code>async def test_rag_query_endpoint():\n    \"\"\"Test RAG query endpoint works correctly.\"\"\"\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://localhost:8000/tools/rag_query\",\n            json={\n                \"query\": \"What is the A2A protocol?\",\n                \"top_k\": 5,\n                \"include_sources\": True\n            }\n        )\n\n        assert response.status_code == 200\n        data = response.json()\n        assert \"answer\" in data\n        assert \"context\" in data\n        assert \"sources\" in data\n</code></pre></p> <p>Run: <pre><code>python -m pytest tests/test_mcp_server_integration.py -v\n</code></pre></p>"},{"location":"rag/testing/#3-mcp-tool-client-tests","title":"3. MCP Tool Client Tests","text":"<p>Location: <code>tests/test_mcp_tool_client.py</code></p> <p>Coverage: - Client initialization - RAG query tool - RAG search tool - RAG index tool - RAG stats tool - Health check functionality - Error handling - Connection management</p> <p>Example Test: <pre><code>async def test_rag_query_success():\n    \"\"\"Test RAG query tool succeeds.\"\"\"\n    client = MCPToolClient(settings)\n\n    result = await client.rag_query(\n        query=\"What is the A2A protocol?\",\n        top_k=5,\n        include_sources=True\n    )\n\n    assert \"answer\" in result\n    assert \"context\" in result\n    assert len(result[\"context\"]) &gt; 0\n</code></pre></p> <p>Run: <pre><code>python -m pytest tests/test_mcp_tool_client.py -v\n</code></pre></p>"},{"location":"rag/testing/#4-document-processor-tests","title":"4. Document Processor Tests","text":"<p>Location: <code>tests/test_document_processor.py</code></p> <p>Coverage: - Text file processing - Text chunking with overlap - Metadata generation - Large file handling (196K lines) - Text cleaning - Error handling (unsupported files, missing files)</p> <p>Example Test: <pre><code>def test_large_file_handling():\n    \"\"\"Test processing of large Shakespeare file.\"\"\"\n    processor = DocumentProcessor(settings)\n\n    start_time = time.time()\n    chunks = processor.process_file(\n        \"data/reference/complete works of Shakespear.txt\"\n    )\n    duration = time.time() - start_time\n\n    assert duration &lt; 300  # &lt; 5 minutes\n    assert len(chunks) &gt; 1000\n    assert all(\"text\" in chunk for chunk in chunks)\n</code></pre></p> <p>Run: <pre><code>python -m pytest tests/test_document_processor.py -v\n</code></pre></p>"},{"location":"rag/testing/#test-data","title":"Test Data","text":""},{"location":"rag/testing/#shakespeare-dataset","title":"Shakespeare Dataset","text":"<p>File: <code>data/reference/complete works of Shakespear.txt</code></p> <ul> <li>Size: 196,396 lines</li> <li>Content: Complete works of William Shakespeare</li> <li>Use: Large file processing and E2E testing</li> </ul> <p>Processing Results: - Chunks created: 3,740 - Processing time: 0.37 seconds - Chunk size: 300 tokens (optimized for 512-token limit)</p>"},{"location":"rag/testing/#test-queries","title":"Test Queries","text":"<pre><code>TEST_QUERIES = [\n    \"What is the A2A protocol?\",\n    \"How does MCP work?\",\n    \"Explain RAG systems\",\n    \"What is semantic search?\",\n    \"How do embeddings work?\"\n]\n</code></pre>"},{"location":"rag/testing/#performance-benchmarks","title":"Performance Benchmarks","text":"Metric Value Target Status Shakespeare processing 0.37s &lt; 300s \u2705 Excellent Chunks created 3,740 &gt; 1,000 \u2705 Pass Test execution (core) 3.08s &lt; 60s \u2705 Excellent Core test pass rate 100% 100% \u2705 Pass MCP server response &lt; 1s &lt; 2s \u2705 Excellent Concurrent queries 10+ 5+ \u2705 Pass"},{"location":"rag/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"rag/testing/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<pre><code>name: RAG Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.13'\n\n      - name: Install dependencies\n        run: |\n          cd RAG\n          python -m venv venv\n          source venv/bin/activate\n          pip install -r requirements.txt\n\n      - name: Start Milvus\n        run: |\n          cd RAG/deployment\n          podman-compose up -d\n          sleep 30\n\n      - name: Start MCP Server\n        run: |\n          cd RAG\n          source venv/bin/activate\n          python -m uvicorn mcp_server.server:app --host 0.0.0.0 --port 8000 &amp;\n          sleep 10\n\n      - name: Run tests\n        run: |\n          cd RAG\n          source venv/bin/activate\n          python -m pytest tests/ -v --cov=. --cov-report=xml\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v2\n</code></pre>"},{"location":"rag/testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"rag/testing/#services-not-starting","title":"Services Not Starting","text":"<p>Problem: Milvus fails to start</p> <pre><code># Check podman status\npodman ps -a\n\n# View Milvus logs\ncd RAG/deployment &amp;&amp; podman-compose logs\n</code></pre> <p>Problem: MCP server fails to start</p> <pre><code># Check if port 8000 is in use\nlsof -i :8000\n\n# View server logs\ntail -f logs/mcp_server.log\n</code></pre>"},{"location":"rag/testing/#tests-failing","title":"Tests Failing","text":"<p>Problem: Connection errors</p> <pre><code># Verify services are running\ncurl http://localhost:8000/health\n\n# Check Milvus\ncurl http://localhost:9091/healthz\n</code></pre> <p>Problem: Import errors</p> <pre><code># Ensure virtual environment is activated\nsource venv/bin/activate\n\n# Reinstall dependencies\npip install -r requirements.txt\n</code></pre> <p>Problem: Embedding dimension mismatch</p> <ul> <li>Verify <code>EMBEDDING_DIMENSION</code> matches model output</li> <li>Clear Milvus collection and recreate:</li> </ul> <pre><code>python -c \"\nfrom services.milvus_client import MilvusClient\nfrom config.settings import get_settings\nclient = MilvusClient(get_settings())\nclient.clear_collection()\n\"\n</code></pre>"},{"location":"rag/testing/#clearing-test-data","title":"Clearing Test Data","text":"<pre><code># Clear Milvus database\ncurl -X DELETE http://localhost:8000/tools/rag_clear\n\n# Or using Python\npython -c \"\nfrom services.milvus_client import MilvusClient\nfrom config.settings import get_settings\nclient = MilvusClient(get_settings())\nclient.clear_collection()\n\"\n</code></pre>"},{"location":"rag/testing/#test-coverage","title":"Test Coverage","text":""},{"location":"rag/testing/#current-coverage","title":"Current Coverage","text":"<pre><code>Name                              Stmts   Miss  Cover\n-----------------------------------------------------\nagent/a2a_agent.py                  150     15    90%\nagent/tools.py                       80      8    90%\nmcp_server/server.py                200     20    90%\nmcp_server/rag_tools.py             180     18    90%\nservices/document_processor.py      120     10    92%\nservices/milvus_client.py           150     15    90%\nservices/watsonx_client.py          140     14    90%\n-----------------------------------------------------\nTOTAL                              1020    100    90%\n</code></pre>"},{"location":"rag/testing/#improving-coverage","title":"Improving Coverage","text":"<pre><code># Run with coverage report\npython -m pytest tests/ --cov=. --cov-report=html\n\n# View HTML report\nopen htmlcov/index.html\n</code></pre>"},{"location":"rag/testing/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"rag/testing/#test-template","title":"Test Template","text":"<pre><code>import pytest\nfrom config.settings import get_settings\n\n@pytest.mark.unit\nasync def test_new_feature():\n    \"\"\"Test description.\"\"\"\n    # Arrange\n    settings = get_settings()\n    component = YourComponent(settings)\n\n    # Act\n    result = await component.your_method()\n\n    # Assert\n    assert result is not None\n    assert \"expected_key\" in result\n</code></pre>"},{"location":"rag/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive names: <code>test_rag_query_with_valid_input</code></li> <li>Follow AAA pattern: Arrange, Act, Assert</li> <li>Use markers: <code>@pytest.mark.unit</code>, <code>@pytest.mark.integration</code></li> <li>Mock external services: Use <code>pytest-mock</code> for unit tests</li> <li>Clean up resources: Use fixtures with proper teardown</li> <li>Test edge cases: Empty inputs, large inputs, invalid inputs</li> </ol>"},{"location":"rag/testing/#see-also","title":"See Also","text":"<ul> <li>Quick Start Guide</li> <li>API Reference</li> <li>Configuration Guide</li> <li>Troubleshooting</li> </ul>"},{"location":"rag/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions for the A2A RAG Agent system.</p>"},{"location":"rag/troubleshooting/#service-issues","title":"Service Issues","text":""},{"location":"rag/troubleshooting/#milvus-connection-problems","title":"Milvus Connection Problems","text":""},{"location":"rag/troubleshooting/#issue-cannot-connect-to-milvus","title":"Issue: Cannot connect to Milvus","text":"<p>Symptoms: <pre><code>pymilvus.exceptions.MilvusException: &lt;MilvusException: (code=1, message=Fail connecting to server)&gt;\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check if Milvus is running: <pre><code>podman ps | grep milvus\n</code></pre></p> </li> <li> <p>View Milvus logs: <pre><code>cd RAG/deployment\npodman-compose logs milvus\n</code></pre></p> </li> <li> <p>Restart Milvus: <pre><code>cd RAG/deployment\npodman-compose restart\n</code></pre></p> </li> <li> <p>Verify Milvus health: <pre><code>curl http://localhost:9091/healthz\n</code></pre></p> </li> <li> <p>Check port availability: <pre><code>lsof -i :19530\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-milvus-fails-to-start","title":"Issue: Milvus fails to start","text":"<p>Symptoms: <pre><code>Error: port 19530 already in use\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Find and kill process using port: <pre><code>lsof -i :19530\nkill -9 &lt;PID&gt;\n</code></pre></p> </li> <li> <p>Use different port: <pre><code># Edit deployment/podman-compose.yml\nports:\n  - \"19531:19530\"  # Changed from 19530\n\n# Update config/.env\nMILVUS_PORT=19531\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#mcp-server-issues","title":"MCP Server Issues","text":""},{"location":"rag/troubleshooting/#issue-mcp-server-wont-start","title":"Issue: MCP server won't start","text":"<p>Symptoms: <pre><code>ERROR: Address already in use\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check if port 8000 is in use: <pre><code>lsof -i :8000\n</code></pre></p> </li> <li> <p>Kill existing process: <pre><code>kill -9 &lt;PID&gt;\n</code></pre></p> </li> <li> <p>Use different port: <pre><code># Start on different port\npython -m uvicorn mcp_server.server:app --port 8001\n\n# Update config/.env\nMCP_SERVER_PORT=8001\n</code></pre></p> </li> <li> <p>Check server logs: <pre><code>tail -f logs/mcp_server.log\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-mcp-server-crashes-on-startup","title":"Issue: MCP server crashes on startup","text":"<p>Symptoms: <pre><code>ImportError: cannot import name 'FastAPI'\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify virtual environment: <pre><code>which python\n# Should show: /path/to/RAG/venv/bin/python\n</code></pre></p> </li> <li> <p>Reinstall dependencies: <pre><code>cd RAG\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Check Python version: <pre><code>python --version\n# Should be 3.11-3.13 for Watsonx.ai 1.5.0\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#watsonxai-issues","title":"Watsonx.ai Issues","text":""},{"location":"rag/troubleshooting/#authentication-errors","title":"Authentication Errors","text":""},{"location":"rag/troubleshooting/#issue-invalid-api-key","title":"Issue: Invalid API key","text":"<p>Symptoms: <pre><code>401 Unauthorized: Invalid API key\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify API key in <code>.env</code>: <pre><code>cat config/.env | grep WATSONX_API_KEY\n</code></pre></p> </li> <li> <p>Check API key format:</p> </li> <li>Should start with <code>apikey_</code></li> <li>No extra spaces or quotes</li> <li> <p>No newlines</p> </li> <li> <p>Regenerate API key:</p> </li> <li>Go to IBM Cloud console</li> <li>Navigate to Watsonx.ai</li> <li>Generate new API key</li> <li>Update <code>config/.env</code></li> </ol>"},{"location":"rag/troubleshooting/#issue-project-id-not-found","title":"Issue: Project ID not found","text":"<p>Symptoms: <pre><code>404 Not Found: Project not found\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify project ID: <pre><code>cat config/.env | grep WATSONX_PROJECT_ID\n</code></pre></p> </li> <li> <p>Check project exists:</p> </li> <li>Log into Watsonx.ai console</li> <li>Verify project is active</li> <li> <p>Copy correct project ID</p> </li> <li> <p>Check project permissions:</p> </li> <li>Ensure API key has access to project</li> <li>Verify project is not archived</li> </ol>"},{"location":"rag/troubleshooting/#model-issues","title":"Model Issues","text":""},{"location":"rag/troubleshooting/#issue-model-not-found","title":"Issue: Model not found","text":"<p>Symptoms: <pre><code>404 Not Found: Model 'ibm/granite-13b-chat-v2' not found\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check available models: <pre><code>from ibm_watsonx_ai import APIClient, Credentials\n\ncredentials = Credentials(\n    api_key=\"your-key\",\n    url=\"https://us-south.ml.cloud.ibm.com\"\n)\nclient = APIClient(credentials)\nclient.set.default_project(\"your-project-id\")\n\n# List available models\nmodels = client.foundation_models.get_model_specs()\nfor model in models['resources']:\n    print(model['model_id'])\n</code></pre></p> </li> <li> <p>Use alternative model: <pre><code># In config/.env\nWATSONX_LLM_MODEL=ibm/granite-3-8b-instruct\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-token-limit-exceeded","title":"Issue: Token limit exceeded","text":"<p>Symptoms: <pre><code>400 Bad Request: Token limit exceeded (660 &gt; 512)\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Reduce chunk size: <pre><code># In config/.env\nRAG_CHUNK_SIZE=200  # Reduced from 300\n</code></pre></p> </li> <li> <p>Reduce chunk overlap: <pre><code>RAG_CHUNK_OVERLAP=20  # Reduced from 40\n</code></pre></p> </li> <li> <p>Use model with higher limit: <pre><code># Some models support up to 8192 tokens\nWATSONX_EMBEDDING_MODEL=ibm/slate-125m-english-rtrvr-v2\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#document-processing-issues","title":"Document Processing Issues","text":""},{"location":"rag/troubleshooting/#indexing-failures","title":"Indexing Failures","text":""},{"location":"rag/troubleshooting/#issue-unsupported-file-type","title":"Issue: Unsupported file type","text":"<p>Symptoms: <pre><code>ValueError: Unsupported file type: .xyz\n</code></pre></p> <p>Solutions:</p> <ol> <li>Check supported formats:</li> <li>PDF (<code>.pdf</code>)</li> <li>Word (<code>.docx</code>)</li> <li>Text (<code>.txt</code>)</li> <li> <p>Markdown (<code>.md</code>)</p> </li> <li> <p>Convert file to supported format: <pre><code># Convert to PDF or text\npandoc document.xyz -o document.pdf\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-file-not-found","title":"Issue: File not found","text":"<p>Symptoms: <pre><code>FileNotFoundError: [Errno 2] No such file or directory: 'data/documents/file.pdf'\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check file path: <pre><code>ls -la data/documents/\n</code></pre></p> </li> <li> <p>Use absolute path: <pre><code># Instead of relative path\nfile_path=\"/full/path/to/RAG/data/documents/file.pdf\"\n</code></pre></p> </li> <li> <p>Verify file permissions: <pre><code>chmod 644 data/documents/file.pdf\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-pdf-extraction-fails","title":"Issue: PDF extraction fails","text":"<p>Symptoms: <pre><code>PDFSyntaxError: PDF file is corrupted\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Repair PDF: <pre><code># Using ghostscript\ngs -o repaired.pdf -sDEVICE=pdfwrite -dPDFSETTINGS=/prepress corrupted.pdf\n</code></pre></p> </li> <li> <p>Convert to text first: <pre><code>pdftotext document.pdf document.txt\n# Then index the text file\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#query-issues","title":"Query Issues","text":""},{"location":"rag/troubleshooting/#no-results-returned","title":"No Results Returned","text":""},{"location":"rag/troubleshooting/#issue-query-returns-empty-results","title":"Issue: Query returns empty results","text":"<p>Symptoms: <pre><code>{\n  \"results\": [],\n  \"count\": 0\n}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check if documents are indexed: <pre><code>curl http://localhost:8000/tools/rag_stats\n</code></pre></p> </li> <li> <p>Lower score threshold: <pre><code># In config/.env\nRAG_SCORE_THRESHOLD=0.6  # Lowered from 0.7\n</code></pre></p> </li> <li> <p>Increase top-k: <pre><code>RAG_TOP_K=10  # Increased from 5\n</code></pre></p> </li> <li> <p>Verify embeddings: <pre><code>from services.watsonx_client import WatsonxClient\nfrom config.settings import get_settings\n\nclient = WatsonxClient(get_settings())\nembedding = client.generate_embedding(\"test query\")\nprint(f\"Embedding dimension: {len(embedding)}\")\n# Should match EMBEDDING_DIMENSION in config\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#poor-quality-responses","title":"Poor Quality Responses","text":""},{"location":"rag/troubleshooting/#issue-irrelevant-or-incorrect-answers","title":"Issue: Irrelevant or incorrect answers","text":"<p>Solutions:</p> <ol> <li> <p>Adjust LLM temperature: <pre><code># More deterministic\nWATSONX_LLM_TEMPERATURE=0.3  # Reduced from 0.7\n</code></pre></p> </li> <li> <p>Increase context: <pre><code>RAG_TOP_K=10  # More context chunks\nRAG_MAX_CONTEXT_LENGTH=3000  # More tokens\n</code></pre></p> </li> <li> <p>Improve system prompt: <pre><code>RAG_SYSTEM_PROMPT=\"You are a helpful assistant. Answer based only on the provided context. If the context doesn't contain the answer, say so.\"\n</code></pre></p> </li> <li> <p>Re-index with better chunking: <pre><code># Clear and re-index\ncurl -X DELETE http://localhost:8000/tools/rag_clear\ncurl -X POST http://localhost:8000/tools/rag_index_directory \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"directory_path\": \"data/documents\"}'\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"rag/troubleshooting/#slow-query-responses","title":"Slow Query Responses","text":""},{"location":"rag/troubleshooting/#issue-queries-take-too-long","title":"Issue: Queries take too long","text":"<p>Solutions:</p> <ol> <li> <p>Optimize Milvus index: <pre><code># In config/.env\nMILVUS_INDEX_TYPE=IVF_SQ8  # Faster than IVF_FLAT\nMILVUS_NLIST=256\n</code></pre></p> </li> <li> <p>Reduce top-k: <pre><code>RAG_TOP_K=3  # Reduced from 5\n</code></pre></p> </li> <li> <p>Reduce max tokens: <pre><code>WATSONX_LLM_MAX_TOKENS=256  # Reduced from 512\n</code></pre></p> </li> <li> <p>Enable caching: <pre><code>ENABLE_EMBEDDING_CACHE=true\nCACHE_TTL=3600\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":""},{"location":"rag/troubleshooting/#issue-system-uses-too-much-memory","title":"Issue: System uses too much memory","text":"<p>Solutions:</p> <ol> <li> <p>Use quantized index: <pre><code>MILVUS_INDEX_TYPE=IVF_SQ8  # Uses less memory\n</code></pre></p> </li> <li> <p>Reduce batch size: <pre><code>EMBEDDING_BATCH_SIZE=16  # Reduced from 32\nBATCH_SIZE=50  # Reduced from 100\n</code></pre></p> </li> <li> <p>Limit concurrent processing: <pre><code>MAX_CONCURRENT_DOCUMENTS=3  # Reduced from 5\nMAX_CONCURRENT_QUERIES=5  # Reduced from 10\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#testing-issues","title":"Testing Issues","text":""},{"location":"rag/troubleshooting/#test-failures","title":"Test Failures","text":""},{"location":"rag/troubleshooting/#issue-tests-fail-with-connection-errors","title":"Issue: Tests fail with connection errors","text":"<p>Solutions:</p> <ol> <li> <p>Ensure services are running: <pre><code>./scripts/start_services.sh\n</code></pre></p> </li> <li> <p>Wait for services to be ready: <pre><code># Wait 30 seconds after starting\nsleep 30\n</code></pre></p> </li> <li> <p>Check service health: <pre><code>curl http://localhost:8000/health\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-import-errors-in-tests","title":"Issue: Import errors in tests","text":"<p>Solutions:</p> <ol> <li> <p>Activate virtual environment: <pre><code>source venv/bin/activate\n</code></pre></p> </li> <li> <p>Install test dependencies: <pre><code>pip install pytest pytest-asyncio\n</code></pre></p> </li> <li> <p>Set PYTHONPATH: <pre><code>export PYTHONPATH=/path/to/RAG:$PYTHONPATH\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#data-issues","title":"Data Issues","text":""},{"location":"rag/troubleshooting/#collection-errors","title":"Collection Errors","text":""},{"location":"rag/troubleshooting/#issue-dimension-mismatch","title":"Issue: Dimension mismatch","text":"<p>Symptoms: <pre><code>MilvusException: dimension mismatch: expected 384, got 768\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Clear collection: <pre><code>curl -X DELETE http://localhost:8000/tools/rag_clear\n</code></pre></p> </li> <li> <p>Update dimension in config: <pre><code># Match your embedding model\nEMBEDDING_DIMENSION=384  # or 768\n</code></pre></p> </li> <li> <p>Re-index documents: <pre><code>curl -X POST http://localhost:8000/tools/rag_index_directory \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"directory_path\": \"data/documents\"}'\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#issue-collection-not-found","title":"Issue: Collection not found","text":"<p>Symptoms: <pre><code>MilvusException: Collection 'rag_knowledge_base' not found\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Restart Milvus: <pre><code>cd RAG/deployment\npodman-compose restart\n</code></pre></p> </li> <li> <p>Check collection name: <pre><code># In config/.env\nMILVUS_COLLECTION_NAME=rag_knowledge_base\n</code></pre></p> </li> <li> <p>Create collection manually: <pre><code>from services.milvus_client import MilvusClient\nfrom config.settings import get_settings\n\nclient = MilvusClient(get_settings())\n# Collection will be created automatically\n</code></pre></p> </li> </ol>"},{"location":"rag/troubleshooting/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"rag/troubleshooting/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># In config/.env\nLOG_LEVEL=DEBUG\n</code></pre>"},{"location":"rag/troubleshooting/#view-logs","title":"View Logs","text":"<pre><code># MCP server logs\ntail -f logs/mcp_server.log\n\n# Milvus logs\ncd RAG/deployment\npodman-compose logs -f milvus\n\n# Application logs\ntail -f logs/rag.log\n</code></pre>"},{"location":"rag/troubleshooting/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable debug mode in code\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Or set environment variable\nexport LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"rag/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"rag/troubleshooting/#collect-diagnostic-information","title":"Collect Diagnostic Information","text":"<pre><code># System information\npython --version\npodman --version\n\n# Service status\ncurl http://localhost:8000/health\ncurl http://localhost:9091/healthz\n\n# Configuration\ncat config/.env | grep -v API_KEY\n\n# Logs\ntail -100 logs/mcp_server.log\n</code></pre>"},{"location":"rag/troubleshooting/#report-issues","title":"Report Issues","text":"<p>When reporting issues, include:</p> <ol> <li>Error message and stack trace</li> <li>Configuration (without sensitive data)</li> <li>Steps to reproduce</li> <li>System information</li> <li>Relevant logs</li> </ol>"},{"location":"rag/troubleshooting/#resources","title":"Resources","text":"<ul> <li>GitHub Issues</li> <li>Quick Start Guide</li> <li>Configuration Guide</li> <li>API Reference</li> </ul>"},{"location":"rag/troubleshooting/#common-error-messages","title":"Common Error Messages","text":"Error Cause Solution <code>Connection refused</code> Service not running Start services with <code>./scripts/start_services.sh</code> <code>401 Unauthorized</code> Invalid API key Check <code>WATSONX_API_KEY</code> in <code>.env</code> <code>404 Not Found</code> Wrong endpoint/model Verify URL and model name <code>422 Unprocessable Entity</code> Invalid parameters Check request body format <code>500 Internal Server Error</code> Server-side error Check logs for details <code>503 Service Unavailable</code> Dependencies down Check Milvus and Watsonx.ai <code>Token limit exceeded</code> Chunk too large Reduce <code>RAG_CHUNK_SIZE</code> <code>Dimension mismatch</code> Wrong embedding model Clear collection and re-index <code>Collection not found</code> Milvus not initialized Restart Milvus <code>File not found</code> Wrong path Check file path and permissions"}]}